{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee5186da",
   "metadata": {},
   "source": [
    "# Chapter 8: Dictionary Mastery for VLSI Professionals üìö\n",
    "\n",
    "## üéØ **Learning Objectives**\n",
    "Master Python dictionaries for professional VLSI automation:\n",
    "\n",
    "### **Core Dictionary Concepts**\n",
    "- Dictionary creation, mutability, and key-value relationships\n",
    "- Hash tables, key requirements, and performance characteristics\n",
    "- Iteration patterns and membership testing\n",
    "\n",
    "### **Essential Dictionary Methods (15+ methods)**\n",
    "- **Access**: `.get()`, `.setdefault()`, `[]` operator\n",
    "- **Modification**: `.update()`, `.pop()`, `.popitem()`, `.clear()`\n",
    "- **Views**: `.keys()`, `.values()`, `.items()`\n",
    "- **Copying**: `.copy()`, shallow vs deep copy\n",
    "- **Querying**: `in` operator, `.keys()`, `.values()`\n",
    "\n",
    "### **VLSI Applications**\n",
    "- **Design Databases**: Instance properties, net attributes, cell libraries\n",
    "- **Configuration Management**: Tool settings, corner definitions\n",
    "- **Lookup Tables**: Pin mappings, timing models, power data\n",
    "- **Results Processing**: Metric collection, report aggregation\n",
    "\n",
    "---\n",
    "\n",
    "## üîß **Why Dictionaries Matter in VLSI**\n",
    "Dictionaries are essential for VLSI data management:\n",
    "- **Instance Properties**: `{'name': 'cpu_core', 'area': 1250.5, 'power': 0.82}`\n",
    "- **Pin Mappings**: `{'clk': 'A1', 'reset_n': 'A2', 'data[0]': 'B1'}`\n",
    "- **Tool Configuration**: `{'corner': 'ss_0p72v_125c', 'effort': 'high'}`\n",
    "- **Results Database**: Fast lookup and aggregation of design metrics\n",
    "- **Hierarchical Data**: Nested structures for complex design information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbd2faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DICTIONARY FUNDAMENTALS AND CREATION\n",
    "# ====================================\n",
    "# Essential dictionary operations for VLSI automation\n",
    "\n",
    "print(\"üìö DICTIONARY FUNDAMENTALS AND CREATION\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# =============================================================================\n",
    "# DICTIONARY CREATION METHODS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìù DICTIONARY CREATION METHODS:\")\n",
    "\n",
    "# Method 1: Literal creation with {}\n",
    "instance_props = {\n",
    "    'name': 'cpu_core',\n",
    "    'type': 'CORE',\n",
    "    'area': 1250.5,\n",
    "    'power': 0.825,\n",
    "    'instances': 125000\n",
    "}\n",
    "print(f\"   Instance properties: {instance_props}\")\n",
    "\n",
    "# Method 2: dict() constructor\n",
    "timing_corner = dict(corner='ss_0p72v_125c', voltage=0.72, temperature=125)\n",
    "empty_dict = dict()\n",
    "print(f\"   Timing corner: {timing_corner}\")\n",
    "print(f\"   Empty dict: {empty_dict}\")\n",
    "\n",
    "# Method 3: From sequences\n",
    "pin_names = ['clk', 'reset_n', 'data_in', 'data_out']\n",
    "pin_locations = ['A1', 'A2', 'B1-B32', 'C1-C32']\n",
    "pin_mapping = dict(zip(pin_names, pin_locations))\n",
    "print(f\"   Pin mapping: {pin_mapping}\")\n",
    "\n",
    "# Method 4: Dictionary comprehension\n",
    "instance_areas = {f'inst_{i}': i * 10.5 for i in range(5)}\n",
    "power_by_corner = {corner: 0.8 + i*0.1 for i, corner in enumerate(['ss', 'tt', 'ff'])}\n",
    "print(f\"   Instance areas: {instance_areas}\")\n",
    "print(f\"   Power by corner: {power_by_corner}\")\n",
    "\n",
    "# Method 5: From key-value pairs\n",
    "config_pairs = [('synthesis', 'dc_shell'), ('place_route', 'innovus'), ('timing', 'tempus')]\n",
    "tool_config = dict(config_pairs)\n",
    "print(f\"   Tool config: {tool_config}\")\n",
    "\n",
    "# =============================================================================\n",
    "# DICTIONARY PROPERTIES AND KEY REQUIREMENTS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüîç DICTIONARY PROPERTIES AND KEY REQUIREMENTS:\")\n",
    "\n",
    "# Basic properties\n",
    "design_info = {\n",
    "    'name': 'cpu_core',\n",
    "    'technology': 'tsmc28',\n",
    "    'area': 1250.5,\n",
    "    'frequency': 1000.0\n",
    "}\n",
    "\n",
    "print(f\"   Design info: {design_info}\")\n",
    "print(f\"   Length: {len(design_info)} key-value pairs\")\n",
    "print(f\"   Type: {type(design_info).__name__}\")\n",
    "print(f\"   Memory ID: {id(design_info)}\")\n",
    "\n",
    "# Key requirements and restrictions\n",
    "print(f\"\\n   Valid key types:\")\n",
    "valid_keys_demo = {\n",
    "    'string_key': 'String keys are most common',\n",
    "    42: 'Integer keys work',\n",
    "    3.14: 'Float keys work',\n",
    "    True: 'Boolean keys work',\n",
    "    ('tuple', 'key'): 'Tuple keys work (immutable)',\n",
    "    # frozenset(['a', 'b']): 'Frozenset keys work'\n",
    "}\n",
    "\n",
    "for key, value in valid_keys_demo.items():\n",
    "    print(f\"     {type(key).__name__}: {key} ‚Üí {value}\")\n",
    "\n",
    "# Invalid key types (would cause errors)\n",
    "print(f\"\\n   Invalid key types (would cause TypeError):\")\n",
    "print(f\"     list: [1, 2, 3] - mutable, not hashable\")\n",
    "print(f\"     dict: {'a': 1} - mutable, not hashable\")\n",
    "print(f\"     set: {1, 2, 3} - mutable, not hashable\")\n",
    "\n",
    "# =============================================================================\n",
    "# DICTIONARY ACCESS AND MODIFICATION\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüéØ DICTIONARY ACCESS AND MODIFICATION:\")\n",
    "\n",
    "# Access methods\n",
    "module_data = {\n",
    "    'cpu_core': {'area': 1250.5, 'power': 0.825},\n",
    "    'memory_ctrl': {'area': 890.2, 'power': 0.456},\n",
    "    'io_ring': {'area': 345.7, 'power': 0.123}\n",
    "}\n",
    "\n",
    "print(f\"   Module data: {module_data}\")\n",
    "\n",
    "# Direct access with []\n",
    "cpu_area = module_data['cpu_core']['area']\n",
    "print(f\"   CPU area (direct): {cpu_area}\")\n",
    "\n",
    "# Safe access with .get()\n",
    "cache_area = module_data.get('cache_ctrl', {}).get('area', 'N/A')\n",
    "mem_power = module_data.get('memory_ctrl', {}).get('power', 0.0)\n",
    "print(f\"   Cache area (safe): {cache_area}\")\n",
    "print(f\"   Memory power (safe): {mem_power}\")\n",
    "\n",
    "# Modification examples\n",
    "print(f\"\\n   Before modification: {len(module_data)} modules\")\n",
    "\n",
    "# Add new module\n",
    "module_data['cache_ctrl'] = {'area': 567.8, 'power': 0.234}\n",
    "print(f\"   After adding cache_ctrl: {len(module_data)} modules\")\n",
    "\n",
    "# Modify existing data\n",
    "module_data['cpu_core']['power'] = 0.850  # Updated power\n",
    "print(f\"   Updated CPU power: {module_data['cpu_core']['power']}\")\n",
    "\n",
    "# Membership testing\n",
    "print(f\"\\n   Membership testing:\")\n",
    "modules_to_check = ['cpu_core', 'gpu_core', 'memory_ctrl', 'dsp_core']\n",
    "for module in modules_to_check:\n",
    "    exists = module in module_data\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"     {module}: {status}\")\n",
    "\n",
    "# Iteration patterns\n",
    "print(f\"\\n   Iteration patterns:\")\n",
    "\n",
    "# Iterate over keys\n",
    "print(f\"     Keys: {list(module_data.keys())}\")\n",
    "\n",
    "# Iterate over values\n",
    "total_area = sum(data['area'] for data in module_data.values())\n",
    "print(f\"     Total area: {total_area:.1f}\")\n",
    "\n",
    "# Iterate over key-value pairs\n",
    "print(f\"     Module summary:\")\n",
    "for module, data in module_data.items():\n",
    "    print(f\"       {module}: {data['area']:.1f} area, {data['power']:.3f} power\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ef0e12",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è **Essential Dictionary Methods for VLSI Automation**\n",
    "\n",
    "Master these 15+ dictionary methods for professional VLSI development:\n",
    "\n",
    "### **Access and Retrieval Methods**\n",
    "- `.get(key, default)`: Safe access with default value\n",
    "- `.setdefault(key, default)`: Get or set default value\n",
    "- `[key]`: Direct access (raises KeyError if missing)\n",
    "\n",
    "### **Modification Methods**\n",
    "- `.update(other)`: Merge dictionaries or update multiple keys\n",
    "- `.pop(key, default)`: Remove and return value\n",
    "- `.popitem()`: Remove and return last key-value pair\n",
    "- `.clear()`: Remove all items\n",
    "- `del dict[key]`: Delete specific key\n",
    "\n",
    "### **View Methods (Dictionary Views)**\n",
    "- `.keys()`: Get all keys as view object\n",
    "- `.values()`: Get all values as view object\n",
    "- `.items()`: Get all key-value pairs as view object\n",
    "\n",
    "### **Copying Methods**\n",
    "- `.copy()`: Create shallow copy\n",
    "- `dict(original)`: Constructor copy\n",
    "- `copy.deepcopy()`: Create deep copy for nested dictionaries\n",
    "\n",
    "### **Utility Methods**\n",
    "- `.fromkeys(keys, value)`: Create dictionary from keys with same value\n",
    "\n",
    "**üí° Pro Tip**: Dictionary views are dynamic - they reflect changes to the original dictionary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83168065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPREHENSIVE DICTIONARY METHODS DEMONSTRATION\n",
    "# ===============================================\n",
    "# Master all essential dictionary methods with VLSI examples\n",
    "\n",
    "print(\"üõ†Ô∏è COMPREHENSIVE DICTIONARY METHODS DEMONSTRATION\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# =============================================================================\n",
    "# ACCESS AND RETRIEVAL METHODS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüîç ACCESS AND RETRIEVAL METHODS:\")\n",
    "\n",
    "# Sample design database\n",
    "design_db = {\n",
    "    'cpu_core': {'area': 1250.5, 'power': 0.825, 'freq': 1000},\n",
    "    'memory_ctrl': {'area': 890.2, 'power': 0.456, 'freq': 800},\n",
    "    'io_ring': {'area': 345.7, 'power': 0.123, 'freq': 500}\n",
    "}\n",
    "\n",
    "print(f\"   Design database: {list(design_db.keys())}\")\n",
    "\n",
    "# .get() method - safe access\n",
    "cpu_area = design_db.get('cpu_core', {}).get('area', 0.0)\n",
    "gpu_area = design_db.get('gpu_core', {}).get('area', 0.0)  # Missing module\n",
    "print(f\"   CPU area: {cpu_area}\")\n",
    "print(f\"   GPU area (missing): {gpu_area}\")\n",
    "\n",
    "# .get() with complex defaults\n",
    "default_module = {'area': 0.0, 'power': 0.0, 'freq': 0}\n",
    "cache_data = design_db.get('cache_ctrl', default_module)\n",
    "print(f\"   Cache data (with default): {cache_data}\")\n",
    "\n",
    "# .setdefault() - get or create with default\n",
    "timing_data = {}\n",
    "print(f\"   Before setdefault: {timing_data}\")\n",
    "\n",
    "# Initialize corner data\n",
    "ss_slack = timing_data.setdefault('ss_corner', []).append(-0.123)\n",
    "tt_slack = timing_data.setdefault('tt_corner', []).append(0.456)\n",
    "timing_data.setdefault('ss_corner', []).append(-0.089)\n",
    "\n",
    "print(f\"   After setdefault: {timing_data}\")\n",
    "\n",
    "# Direct access comparison\n",
    "try:\n",
    "    missing_data = design_db['missing_module']  # Would raise KeyError\n",
    "except KeyError as e:\n",
    "    print(f\"   Direct access error: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# MODIFICATION METHODS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n‚úèÔ∏è MODIFICATION METHODS:\")\n",
    "\n",
    "# .update() method - merge dictionaries\n",
    "base_config = {'synthesis': 'dc_shell', 'timing': 'tempus'}\n",
    "additional_config = {'place_route': 'innovus', 'timing': 'primetime'}  # Note: 'timing' will be overwritten\n",
    "\n",
    "print(f\"   Base config: {base_config}\")\n",
    "print(f\"   Additional config: {additional_config}\")\n",
    "\n",
    "base_config.update(additional_config)\n",
    "print(f\"   After update(): {base_config}\")\n",
    "\n",
    "# .update() with keyword arguments\n",
    "corner_settings = {'voltage': 0.72, 'temperature': 125}\n",
    "corner_settings.update(process='ss', effort='high', optimize='timing')\n",
    "print(f\"   Corner settings: {corner_settings}\")\n",
    "\n",
    "# .pop() method - remove and return\n",
    "instance_props = {'name': 'cpu', 'area': 1250, 'power': 0.8, 'temp_data': 'remove_me'}\n",
    "print(f\"   Before pop: {instance_props}\")\n",
    "\n",
    "removed_temp = instance_props.pop('temp_data')\n",
    "missing_item = instance_props.pop('missing_key', 'default_value')\n",
    "print(f\"   After pop: {instance_props}\")\n",
    "print(f\"   Removed temp_data: {removed_temp}\")\n",
    "print(f\"   Missing item (with default): {missing_item}\")\n",
    "\n",
    "# .popitem() method - remove last item (Python 3.7+ preserves insertion order)\n",
    "test_dict = {'first': 1, 'second': 2, 'third': 3}\n",
    "print(f\"   Before popitem: {test_dict}\")\n",
    "last_item = test_dict.popitem()\n",
    "print(f\"   After popitem: {test_dict}\")\n",
    "print(f\"   Popped item: {last_item}\")\n",
    "\n",
    "# .clear() method\n",
    "temp_dict = {'a': 1, 'b': 2, 'c': 3}\n",
    "print(f\"   Before clear: {temp_dict}\")\n",
    "temp_dict.clear()\n",
    "print(f\"   After clear: {temp_dict}\")\n",
    "\n",
    "# del statement\n",
    "module_metrics = {'area': 1250, 'power': 0.8, 'temp': 85, 'delete_me': 'temp'}\n",
    "print(f\"   Before del: {module_metrics}\")\n",
    "del module_metrics['delete_me']\n",
    "print(f\"   After del: {module_metrics}\")\n",
    "\n",
    "# =============================================================================\n",
    "# VIEW METHODS AND DICTIONARY VIEWS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüëÅÔ∏è VIEW METHODS AND DICTIONARY VIEWS:\")\n",
    "\n",
    "# Sample timing results\n",
    "timing_results = {\n",
    "    'setup_slack': -0.123,\n",
    "    'hold_slack': 0.456,\n",
    "    'max_delay': 2.5,\n",
    "    'min_delay': 0.8\n",
    "}\n",
    "\n",
    "print(f\"   Timing results: {timing_results}\")\n",
    "\n",
    "# .keys(), .values(), .items() views\n",
    "keys_view = timing_results.keys()\n",
    "values_view = timing_results.values()\n",
    "items_view = timing_results.items()\n",
    "\n",
    "print(f\"   Keys view: {list(keys_view)}\")\n",
    "print(f\"   Values view: {list(values_view)}\")\n",
    "print(f\"   Items view: {list(items_view)}\")\n",
    "\n",
    "# Views are dynamic - they reflect changes\n",
    "print(f\"\\n   Views are dynamic:\")\n",
    "print(f\"   Before adding: {len(keys_view)} keys\")\n",
    "timing_results['power_slack'] = 0.234\n",
    "print(f\"   After adding: {len(keys_view)} keys\")\n",
    "print(f\"   Updated keys: {list(keys_view)}\")\n",
    "\n",
    "# View operations\n",
    "slack_metrics = {'setup_slack', 'hold_slack', 'power_slack'}\n",
    "available_slacks = keys_view & slack_metrics  # Set intersection\n",
    "print(f\"   Available slack metrics: {available_slacks}\")\n",
    "\n",
    "# Iterate over views\n",
    "print(f\"\\n   Processing timing data:\")\n",
    "for metric, value in timing_results.items():\n",
    "    if 'slack' in metric:\n",
    "        status = \"PASS\" if value >= 0 else \"FAIL\"\n",
    "        print(f\"     {metric}: {value:+.3f} ({status})\")\n",
    "\n",
    "# =============================================================================\n",
    "# COPYING METHODS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüìã COPYING METHODS:\")\n",
    "\n",
    "import copy\n",
    "\n",
    "# Original nested dictionary\n",
    "original_design = {\n",
    "    'name': 'cpu_core',\n",
    "    'modules': {\n",
    "        'alu': {'area': 450.2, 'power': 0.3},\n",
    "        'reg_file': {'area': 800.3, 'power': 0.5}\n",
    "    },\n",
    "    'corners': ['ss', 'tt', 'ff']\n",
    "}\n",
    "\n",
    "print(f\"   Original design: {original_design['name']}\")\n",
    "\n",
    "# Shallow copy methods\n",
    "shallow_copy1 = original_design.copy()\n",
    "shallow_copy2 = dict(original_design)\n",
    "\n",
    "# Deep copy\n",
    "deep_copy = copy.deepcopy(original_design)\n",
    "\n",
    "print(f\"   Created copies: shallow (2), deep (1)\")\n",
    "\n",
    "# Modify original\n",
    "original_design['name'] = 'modified_cpu'\n",
    "original_design['modules']['alu']['area'] = 500.0  # Nested modification\n",
    "original_design['corners'].append('slow')  # List modification\n",
    "\n",
    "print(f\"\\n   After modification:\")\n",
    "print(f\"   Original name: {original_design['name']}\")\n",
    "print(f\"   Shallow copy name: {shallow_copy1['name']}\")\n",
    "print(f\"   Deep copy name: {deep_copy['name']}\")\n",
    "\n",
    "print(f\"\\n   ALU area comparison:\")\n",
    "print(f\"   Original: {original_design['modules']['alu']['area']}\")\n",
    "print(f\"   Shallow copy: {shallow_copy1['modules']['alu']['area']} (affected!)\")\n",
    "print(f\"   Deep copy: {deep_copy['modules']['alu']['area']} (protected)\")\n",
    "\n",
    "# .fromkeys() method\n",
    "print(f\"\\nüìù .fromkeys() METHOD:\")\n",
    "\n",
    "# Initialize multiple modules with default values\n",
    "module_names = ['cpu_core', 'memory_ctrl', 'io_ring', 'cache_ctrl']\n",
    "default_stats = {'area': 0.0, 'power': 0.0, 'instances': 0}\n",
    "\n",
    "# Create dictionary with same default for all keys\n",
    "module_stats = dict.fromkeys(module_names, default_stats.copy())\n",
    "print(f\"   Module stats initialized: {list(module_stats.keys())}\")\n",
    "print(f\"   Default values: {module_stats['cpu_core']}\")\n",
    "\n",
    "# Warning: .fromkeys() with mutable default\n",
    "# This creates the SAME object for all keys (usually not desired)\n",
    "shared_default = dict.fromkeys(['a', 'b', 'c'], [])\n",
    "shared_default['a'].append('item')\n",
    "print(f\"\\n   Shared default example:\")\n",
    "print(f\"   Modified 'a': {shared_default['a']}\")\n",
    "print(f\"   'b' also changed: {shared_default['b']} (shared reference!)\")\n",
    "\n",
    "# Better approach for mutable defaults\n",
    "separate_defaults = {key: [] for key in ['a', 'b', 'c']}\n",
    "separate_defaults['a'].append('item')\n",
    "print(f\"   Separate defaults: {separate_defaults}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80790643",
   "metadata": {},
   "source": [
    "## üöÄ **Advanced Dictionary Operations for VLSI**\n",
    "\n",
    "Professional VLSI automation requires sophisticated dictionary techniques:\n",
    "\n",
    "### **Dictionary Comprehensions**\n",
    "Efficient creation and transformation of dictionaries:\n",
    "```python\n",
    "violations = {path: slack for path, slack in timing_data.items() if slack < 0}\n",
    "normalized = {k: v/total for k, v in power_data.items()}\n",
    "```\n",
    "\n",
    "### **Nested Dictionary Processing**\n",
    "- **Design Hierarchies**: Multi-level module organization\n",
    "- **Multi-Corner Data**: Results across process corners\n",
    "- **Complex Configurations**: Tool settings and parameters\n",
    "\n",
    "### **Performance Considerations**\n",
    "- **Hash Table Efficiency**: O(1) average lookup time\n",
    "- **Memory Usage**: Dictionaries vs lists for large datasets\n",
    "- **Key Design**: Choose efficient, collision-resistant keys\n",
    "\n",
    "### **Integration Patterns**\n",
    "- **With Lists**: `[{instance: data} for instance in instances]`\n",
    "- **With Sets**: `set(dictionary.keys())` for unique collections\n",
    "- **With Tuples**: `dict.items()` returns tuple pairs\n",
    "\n",
    "### **Real-World VLSI Applications**\n",
    "- **Design Databases**: Fast lookup of instance properties\n",
    "- **Configuration Management**: Tool and corner settings\n",
    "- **Results Aggregation**: Collect metrics from multiple runs\n",
    "- **Lookup Tables**: Pin maps, timing models, power data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1cdc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADVANCED DICTIONARY OPERATIONS FOR VLSI AUTOMATION\n",
    "# ==================================================\n",
    "# Dictionary comprehensions, nested processing, and real-world applications\n",
    "\n",
    "print(\"üöÄ ADVANCED DICTIONARY OPERATIONS FOR VLSI AUTOMATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# =============================================================================\n",
    "# DICTIONARY COMPREHENSIONS AND TRANSFORMATIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n‚ö° DICTIONARY COMPREHENSIONS AND TRANSFORMATIONS:\")\n",
    "\n",
    "# Sample timing data\n",
    "timing_paths = {\n",
    "    'cpu/reg_a->reg_b': -0.123,\n",
    "    'cpu/reg_c->reg_d': 0.456,\n",
    "    'mem/reg_e->reg_f': -0.089,\n",
    "    'io/reg_g->reg_h': 0.234,\n",
    "    'cache/reg_i->reg_j': -0.567\n",
    "}\n",
    "\n",
    "print(f\"   Original timing data: {len(timing_paths)} paths\")\n",
    "\n",
    "# Filter violations using comprehension\n",
    "violations = {path: slack for path, slack in timing_paths.items() if slack < 0}\n",
    "passing_paths = {path: slack for path, slack in timing_paths.items() if slack >= 0}\n",
    "\n",
    "print(f\"   Violations: {len(violations)} paths\")\n",
    "print(f\"   Passing paths: {len(passing_paths)} paths\")\n",
    "\n",
    "# Transform values\n",
    "abs_violations = {path: abs(slack) for path, slack in violations.items()}\n",
    "slack_margins = {path: slack * 1000 for path, slack in passing_paths.items()}  # Convert to ps\n",
    "\n",
    "print(f\"   Absolute violations: {abs_violations}\")\n",
    "print(f\"   Margins in ps: {slack_margins}\")\n",
    "\n",
    "# Complex transformations\n",
    "path_analysis = {\n",
    "    path: {\n",
    "        'slack': slack,\n",
    "        'status': 'PASS' if slack >= 0 else 'FAIL',\n",
    "        'margin_ps': slack * 1000,\n",
    "        'module': path.split('/')[0]\n",
    "    }\n",
    "    for path, slack in timing_paths.items()\n",
    "}\n",
    "\n",
    "print(f\"\\n   Complex analysis sample:\")\n",
    "for path, analysis in list(path_analysis.items())[:2]:\n",
    "    print(f\"     {path}: {analysis}\")\n",
    "\n",
    "# Group by module\n",
    "modules = set(analysis['module'] for analysis in path_analysis.values())\n",
    "by_module = {\n",
    "    module: {\n",
    "        path: data for path, data in path_analysis.items()\n",
    "        if data['module'] == module\n",
    "    }\n",
    "    for module in modules\n",
    "}\n",
    "\n",
    "print(f\"\\n   Grouped by module:\")\n",
    "for module, paths in by_module.items():\n",
    "    violations_count = sum(1 for data in paths.values() if data['status'] == 'FAIL')\n",
    "    print(f\"     {module}: {len(paths)} paths, {violations_count} violations\")\n",
    "\n",
    "# =============================================================================\n",
    "# NESTED DICTIONARY PROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüéØ NESTED DICTIONARY PROCESSING:\")\n",
    "\n",
    "# Multi-corner design database\n",
    "multi_corner_db = {\n",
    "    'cpu_core': {\n",
    "        'ss_corner': {'area': 1250.5, 'power': 0.825, 'freq': 950},\n",
    "        'tt_corner': {'area': 1250.5, 'power': 0.650, 'freq': 1000},\n",
    "        'ff_corner': {'area': 1250.5, 'power': 0.480, 'freq': 1100}\n",
    "    },\n",
    "    'memory_ctrl': {\n",
    "        'ss_corner': {'area': 890.2, 'power': 0.456, 'freq': 800},\n",
    "        'tt_corner': {'area': 890.2, 'power': 0.380, 'freq': 850},\n",
    "        'ff_corner': {'area': 890.2, 'power': 0.290, 'freq': 900}\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"   Multi-corner database: {list(multi_corner_db.keys())}\")\n",
    "\n",
    "# Extract corner-specific data\n",
    "worst_case_power = {\n",
    "    module: max(corner_data['power'] for corner_data in corners.values())\n",
    "    for module, corners in multi_corner_db.items()\n",
    "}\n",
    "\n",
    "best_case_freq = {\n",
    "    module: max(corner_data['freq'] for corner_data in corners.values())\n",
    "    for module, corners in multi_corner_db.items()\n",
    "}\n",
    "\n",
    "print(f\"   Worst case power: {worst_case_power}\")\n",
    "print(f\"   Best case frequency: {best_case_freq}\")\n",
    "\n",
    "# Flatten nested structure\n",
    "flattened_results = {\n",
    "    f\"{module}_{corner}\": metrics\n",
    "    for module, corners in multi_corner_db.items()\n",
    "    for corner, metrics in corners.items()\n",
    "}\n",
    "\n",
    "print(f\"\\n   Flattened results: {len(flattened_results)} entries\")\n",
    "for key in list(flattened_results.keys())[:3]:\n",
    "    print(f\"     {key}: {flattened_results[key]}\")\n",
    "\n",
    "# Aggregate statistics\n",
    "total_power_by_corner = {}\n",
    "for module, corners in multi_corner_db.items():\n",
    "    for corner, metrics in corners.items():\n",
    "        total_power_by_corner.setdefault(corner, 0)\n",
    "        total_power_by_corner[corner] += metrics['power']\n",
    "\n",
    "print(f\"\\n   Total power by corner: {total_power_by_corner}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PERFORMANCE AND EFFICIENCY CONSIDERATIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n‚ö° PERFORMANCE AND EFFICIENCY CONSIDERATIONS:\")\n",
    "\n",
    "import time\n",
    "\n",
    "# Compare lookup performance: list vs dictionary\n",
    "def benchmark_lookup_performance(size=10000):\n",
    "    \"\"\"Compare list and dictionary lookup performance\"\"\"\n",
    "\n",
    "    # Create test data\n",
    "    test_items = [(f\"inst_{i}\", i * 10) for i in range(size)]\n",
    "\n",
    "    # List of tuples\n",
    "    list_data = test_items\n",
    "\n",
    "    # Dictionary\n",
    "    dict_data = dict(test_items)\n",
    "\n",
    "    # Test lookups\n",
    "    search_keys = [f\"inst_{i}\" for i in range(0, size, 100)]  # Every 100th item\n",
    "\n",
    "    # List search (linear)\n",
    "    start = time.perf_counter()\n",
    "    list_results = []\n",
    "    for key in search_keys:\n",
    "        for item_key, value in list_data:\n",
    "            if item_key == key:\n",
    "                list_results.append(value)\n",
    "                break\n",
    "    list_time = time.perf_counter() - start\n",
    "\n",
    "    # Dictionary search (hash table)\n",
    "    start = time.perf_counter()\n",
    "    dict_results = [dict_data[key] for key in search_keys]\n",
    "    dict_time = time.perf_counter() - start\n",
    "\n",
    "    return list_time, dict_time, len(search_keys)\n",
    "\n",
    "# Run performance comparison\n",
    "list_time, dict_time, num_lookups = benchmark_lookup_performance()\n",
    "\n",
    "print(f\"   Lookup performance ({num_lookups} lookups):\")\n",
    "print(f\"     List (linear search): {list_time:.6f} seconds\")\n",
    "print(f\"     Dictionary (hash): {dict_time:.6f} seconds\")\n",
    "print(f\"     Dictionary speedup: {list_time/dict_time:.1f}x faster\")\n",
    "\n",
    "# Memory usage comparison\n",
    "import sys\n",
    "\n",
    "test_size = 1000\n",
    "list_of_tuples = [(f\"key_{i}\", i) for i in range(test_size)]\n",
    "dictionary = {f\"key_{i}\": i for i in range(test_size)}\n",
    "\n",
    "list_memory = sys.getsizeof(list_of_tuples)\n",
    "dict_memory = sys.getsizeof(dictionary)\n",
    "\n",
    "print(f\"\\n   Memory usage ({test_size} items):\")\n",
    "print(f\"     List of tuples: {list_memory:,} bytes\")\n",
    "print(f\"     Dictionary: {dict_memory:,} bytes\")\n",
    "print(f\"     Dictionary overhead: {dict_memory/list_memory:.1f}x\")\n",
    "\n",
    "# =============================================================================\n",
    "# REAL-WORLD VLSI APPLICATIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüîß REAL-WORLD VLSI APPLICATIONS:\")\n",
    "\n",
    "# 1. Pin mapping database\n",
    "pin_mapping_db = {\n",
    "    'functional': {\n",
    "        'clk': {'location': 'A1', 'type': 'input', 'voltage': 1.8},\n",
    "        'reset_n': {'location': 'A2', 'type': 'input', 'voltage': 1.8},\n",
    "        'data_in[31:0]': {'location': 'B1-B32', 'type': 'input', 'voltage': 1.2}\n",
    "    },\n",
    "    'power': {\n",
    "        'VDD_CORE': {'location': 'PWR1-PWR10', 'voltage': 1.2, 'current': 2.5},\n",
    "        'VDD_IO': {'location': 'PWR11-PWR15', 'voltage': 1.8, 'current': 0.8}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Query pin database\n",
    "core_voltage_pins = {\n",
    "    pin: info for category in pin_mapping_db.values()\n",
    "    for pin, info in category.items()\n",
    "    if info.get('voltage') == 1.2\n",
    "}\n",
    "\n",
    "print(f\"   1.2V pins: {list(core_voltage_pins.keys())}\")\n",
    "\n",
    "# 2. Tool configuration management\n",
    "tool_configs = {\n",
    "    'synthesis': {\n",
    "        'tool': 'dc_shell',\n",
    "        'effort': 'high',\n",
    "        'optimization': ['timing', 'area'],\n",
    "        'corners': ['ss_0p72v_125c', 'tt_0p8v_25c']\n",
    "    },\n",
    "    'place_route': {\n",
    "        'tool': 'innovus',\n",
    "        'effort': 'standard',\n",
    "        'optimization': ['timing', 'power'],\n",
    "        'corners': ['ss_0p72v_125c', 'ff_0p88v_m40c']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Generate run configurations\n",
    "run_configs = {\n",
    "    f\"{stage}_{corner}\": {\n",
    "        'stage': stage,\n",
    "        'corner': corner,\n",
    "        'tool': config['tool'],\n",
    "        'effort': config['effort']\n",
    "    }\n",
    "    for stage, config in tool_configs.items()\n",
    "    for corner in config['corners']\n",
    "}\n",
    "\n",
    "print(f\"\\n   Generated run configs: {len(run_configs)}\")\n",
    "for config_name in list(run_configs.keys())[:3]:\n",
    "    print(f\"     {config_name}: {run_configs[config_name]['tool']}\")\n",
    "\n",
    "# 3. Results aggregation and analysis\n",
    "run_results = {\n",
    "    'synthesis_ss_0p72v_125c': {'area': 1250.5, 'timing': -0.123, 'runtime': 45.2},\n",
    "    'synthesis_tt_0p8v_25c': {'area': 1250.5, 'timing': 0.234, 'runtime': 42.8},\n",
    "    'place_route_ss_0p72v_125c': {'area': 1275.8, 'timing': -0.089, 'runtime': 125.6},\n",
    "    'place_route_ff_0p88v_m40c': {'area': 1275.8, 'timing': 0.456, 'runtime': 118.3}\n",
    "}\n",
    "\n",
    "# Analyze results\n",
    "worst_timing = min(result['timing'] for result in run_results.values())\n",
    "total_runtime = sum(result['runtime'] for result in run_results.values())\n",
    "stages_with_violations = [\n",
    "    stage for stage, result in run_results.items()\n",
    "    if result['timing'] < 0\n",
    "]\n",
    "\n",
    "print(f\"\\n   Results analysis:\")\n",
    "print(f\"     Worst timing: {worst_timing:.3f}ns\")\n",
    "print(f\"     Total runtime: {total_runtime:.1f} minutes\")\n",
    "print(f\"     Stages with violations: {len(stages_with_violations)}\")\n",
    "\n",
    "# Summary by stage\n",
    "by_stage = {}\n",
    "for run_name, results in run_results.items():\n",
    "    stage = run_name.split('_')[0]\n",
    "    by_stage.setdefault(stage, []).append(results['timing'])\n",
    "\n",
    "stage_summary = {\n",
    "    stage: {\n",
    "        'best_timing': max(timings),\n",
    "        'worst_timing': min(timings),\n",
    "        'violations': sum(1 for t in timings if t < 0)\n",
    "    }\n",
    "    for stage, timings in by_stage.items()\n",
    "}\n",
    "\n",
    "print(f\"\\n   Stage summary:\")\n",
    "for stage, summary in stage_summary.items():\n",
    "    print(f\"     {stage}: best={summary['best_timing']:+.3f}, \"\n",
    "          f\"worst={summary['worst_timing']:+.3f}, \"\n",
    "          f\"violations={summary['violations']}\")\n",
    "\n",
    "print(f\"\\nüèÜ ADVANCED DICTIONARY OPERATION BENEFITS:\")\n",
    "print(\"‚úÖ **Fast Lookups**: O(1) average time for hash table access\")\n",
    "print(\"‚úÖ **Flexible Keys**: Use strings, numbers, tuples as keys\")\n",
    "print(\"‚úÖ **Nested Structures**: Handle complex hierarchical data\")\n",
    "print(\"‚úÖ **Data Aggregation**: Efficiently collect and analyze results\")\n",
    "print(\"‚úÖ **Configuration Management**: Organize tool and design settings\")\n",
    "print(\"‚úÖ **Database Operations**: Replace simple databases for VLSI data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b64b0d",
   "metadata": {},
   "source": [
    "## üí™ **Practice Exercises: Dictionary Mastery**\n",
    "\n",
    "### **üéØ Exercise 1: Design Database Manager**\n",
    "Create a system to:\n",
    "- Store instance properties (area, power, timing)\n",
    "- Query by module type or property range\n",
    "- Update properties and maintain history\n",
    "- Export filtered results to different formats\n",
    "\n",
    "### **üéØ Exercise 2: Multi-Corner Results Processor**\n",
    "Build a processor that:\n",
    "- Aggregates results from multiple corners\n",
    "- Finds worst-case across all conditions\n",
    "- Generates corner comparison reports\n",
    "- Identifies corner-specific issues\n",
    "\n",
    "### **üéØ Exercise 3: Configuration Validator**\n",
    "Implement a validator for:\n",
    "- Tool configuration consistency checking\n",
    "- Required parameter validation\n",
    "- Default value assignment\n",
    "- Configuration inheritance and overrides\n",
    "\n",
    "### **üéØ Exercise 4: Pin Mapping System**\n",
    "Create a comprehensive system for:\n",
    "- Pin location and property management\n",
    "- Signal-to-pin assignment validation\n",
    "- Package compatibility checking\n",
    "- Pin usage optimization\n",
    "\n",
    "---\n",
    "\n",
    "## üèÜ **Chapter Summary: Dictionary Mastery Achieved**\n",
    "\n",
    "### **‚úÖ Core Concepts Mastered**\n",
    "- **Dictionary Creation**: 5+ methods including comprehensions\n",
    "- **Key Requirements**: Hashable types and immutability\n",
    "- **Essential Methods**: 15+ methods for all dictionary operations\n",
    "\n",
    "### **‚úÖ VLSI Applications**\n",
    "- **Design Databases**: Fast property lookup and storage\n",
    "- **Configuration Management**: Tool and corner settings\n",
    "- **Results Processing**: Metric collection and analysis\n",
    "- **Lookup Tables**: Pin maps, timing models, power data\n",
    "\n",
    "### **‚úÖ Professional Techniques**\n",
    "- **Dictionary Comprehensions**: Efficient data transformation\n",
    "- **Nested Processing**: Complex hierarchical data handling\n",
    "- **Performance Optimization**: Hash table efficiency understanding\n",
    "- **Integration Patterns**: Working with other Python data types\n",
    "\n",
    "### **‚úÖ Advanced Skills**\n",
    "- **Multi-Level Nesting**: Complex data structure management\n",
    "- **Performance Analysis**: Understanding lookup efficiency\n",
    "- **Real-World Applications**: Production-ready VLSI automation\n",
    "\n",
    "**üöÄ Next**: Ready for Chapter 10: Tuple Mastery for Immutable Data Structures!\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
