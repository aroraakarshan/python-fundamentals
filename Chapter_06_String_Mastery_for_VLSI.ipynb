{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e42bd93",
   "metadata": {},
   "source": [
    "# Chapter 6: String Mastery for VLSI Professionals üî§\n",
    "\n",
    "## üéØ **Learning Objectives**\n",
    "By the end of this chapter, you will master Python strings for professional VLSI automation:\n",
    "\n",
    "### **Core String Concepts**\n",
    "- String creation, immutability, and memory management\n",
    "- Unicode handling for international design teams\n",
    "- String indexing, slicing, and iteration patterns\n",
    "\n",
    "### **Essential String Methods (25+ methods)**\n",
    "- **Creation & Conversion**: `str()`, `.encode()`, `.decode()`\n",
    "- **Search & Find**: `.find()`, `.rfind()`, `.index()`, `.count()`\n",
    "- **Validation**: `.startswith()`, `.endswith()`, `.isdigit()`, `.isalpha()`\n",
    "- **Transformation**: `.upper()`, `.lower()`, `.title()`, `.swapcase()`\n",
    "- **Cleaning**: `.strip()`, `.lstrip()`, `.rstrip()`, `.replace()`\n",
    "- **Splitting & Joining**: `.split()`, `.rsplit()`, `.join()`, `.partition()`\n",
    "- **Formatting**: `.format()`, f-strings, `.center()`, `.ljust()`, `.rjust()`\n",
    "\n",
    "### **Advanced VLSI Applications**\n",
    "- **Hierarchical Path Processing**: Module and signal name parsing\n",
    "- **Report Analysis**: Timing, power, and area report extraction\n",
    "- **Script Generation**: TCL/SDC/UPF command automation\n",
    "- **File Management**: Design database organization\n",
    "- **Performance Optimization**: Large-scale string processing\n",
    "\n",
    "### **Professional Techniques**\n",
    "- Regular expressions for complex pattern matching\n",
    "- String performance optimization and memory management\n",
    "- Input validation and security for production environments\n",
    "- Error handling and robust parsing strategies\n",
    "\n",
    "---\n",
    "\n",
    "## üîß **Why Strings Matter in VLSI**\n",
    "\n",
    "In VLSI design automation, strings are everywhere:\n",
    "- **Design Hierarchies**: `cpu_core/alu_unit/adder_inst/sum[31:0]`\n",
    "- **File Paths**: `/designs/cpu_core/implementation/place_route/cpu_core.def`\n",
    "- **Tool Commands**: `create_clock -period 10.0 [get_ports clk]`\n",
    "- **Report Parsing**: Extracting timing violations from million-line reports\n",
    "- **Configuration Files**: Technology libraries and design constraints\n",
    "\n",
    "Mastering strings enables powerful automation that saves hours of manual work daily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f498af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRING FUNDAMENTALS AND CREATION METHODS\n",
    "# =========================================\n",
    "# Deep dive into string creation, properties, and memory behavior\n",
    "\n",
    "print(\"üî§ STRING FUNDAMENTALS AND CREATION METHODS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# =============================================================================\n",
    "# STRING CREATION METHODS - COMPREHENSIVE COVERAGE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìù STRING CREATION METHODS:\")\n",
    "\n",
    "# Method 1: String literals (most common)\n",
    "design_name = \"cpu_core\"  # Single quotes\n",
    "technology = 'tsmc28'     # Double quotes (same as single)\n",
    "print(f\"   Literal creation: '{design_name}' and '{technology}'\")\n",
    "\n",
    "# Method 2: Triple quotes for multi-line strings\n",
    "verilog_module = \"\"\"\n",
    "module cpu_core (\n",
    "    input wire clk,\n",
    "    input wire reset_n,\n",
    "    input wire [31:0] instruction,\n",
    "    output reg [31:0] result\n",
    ");\n",
    "    // Module implementation\n",
    "endmodule\n",
    "\"\"\"\n",
    "print(f\"   Multi-line string length: {len(verilog_module)} characters\")\n",
    "\n",
    "# Method 3: str() constructor\n",
    "instance_count = 125000\n",
    "count_string = str(instance_count)\n",
    "binary_string = str(bin(255))  # Convert binary to string\n",
    "print(f\"   str() constructor: '{count_string}' and '{binary_string}'\")\n",
    "\n",
    "# Method 4: Raw strings (no escape processing)\n",
    "file_path_windows = r\"C:\\designs\\cpu_core\\netlist\\cpu_core.v\"\n",
    "regex_pattern = r\"([a-zA-Z_]\\w*)/(\\w+)\\[(\\d+):(\\d+)\\]\"\n",
    "print(f\"   Raw strings: {file_path_windows}\")\n",
    "print(f\"   Regex pattern: {regex_pattern}\")\n",
    "\n",
    "# Method 5: Formatted strings (f-strings, format, %)\n",
    "corner = \"ss_0p72v_125c\"\n",
    "temperature = 125\n",
    "voltage = 0.72\n",
    "\n",
    "# f-string (Python 3.6+) - preferred method\n",
    "netlist_f = f\"/designs/{design_name}/netlist/{design_name}_{corner}.v\"\n",
    "\n",
    "# .format() method - compatible with older Python\n",
    "sdc_format = \"/designs/{design}/constraints/{design}_{corner}.sdc\".format(\n",
    "    design=design_name, corner=corner\n",
    ")\n",
    "\n",
    "# % formatting (legacy, but still used)\n",
    "report_percent = \"/designs/%s/reports/timing_%s_T%.0fC.rpt\" % (design_name, corner, temperature)\n",
    "\n",
    "print(f\"   f-string: {netlist_f}\")\n",
    "print(f\"   .format(): {sdc_format}\")\n",
    "print(f\"   % format: {report_percent}\")\n",
    "\n",
    "# =============================================================================\n",
    "# STRING PROPERTIES AND IMMUTABILITY\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüîç STRING PROPERTIES AND IMMUTABILITY:\")\n",
    "\n",
    "# Basic string properties\n",
    "signal_path = \"cpu_core/alu_unit/adder_inst/sum[31:0]\"\n",
    "\n",
    "print(f\"   Signal path: '{signal_path}'\")\n",
    "print(f\"   Length: {len(signal_path)} characters\")\n",
    "print(f\"   Memory size: {signal_path.__sizeof__()} bytes\")\n",
    "print(f\"   Type: {type(signal_path).__name__}\")\n",
    "print(f\"   ID (memory location): {id(signal_path)}\")\n",
    "\n",
    "# String immutability demonstration\n",
    "original_signal = \"cpu_core/reg_file\"\n",
    "print(f\"\\n   Original signal: '{original_signal}' (ID: {id(original_signal)})\")\n",
    "\n",
    "# Strings are immutable - operations create new strings\n",
    "modified_signal = original_signal.replace(\"reg_file\", \"cache\")\n",
    "print(f\"   Modified signal: '{modified_signal}' (ID: {id(modified_signal)})\")\n",
    "print(f\"   Original unchanged: '{original_signal}' (ID: {id(original_signal)})\")\n",
    "\n",
    "# This would cause an error (uncomment to see):\n",
    "# original_signal[0] = 'X'  # TypeError: 'str' object does not support item assignment\n",
    "\n",
    "# Memory efficiency - Python interns small strings\n",
    "small_str1 = \"clk\"\n",
    "small_str2 = \"clk\"\n",
    "print(f\"\\n   String interning:\")\n",
    "print(f\"   small_str1 ID: {id(small_str1)}\")\n",
    "print(f\"   small_str2 ID: {id(small_str2)}\")\n",
    "print(f\"   Same object: {small_str1 is small_str2}\")  # True for small strings\n",
    "\n",
    "# =============================================================================\n",
    "# STRING INDEXING AND SLICING\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüéØ STRING INDEXING AND SLICING:\")\n",
    "\n",
    "# Signal name with bus notation\n",
    "bus_signal = \"data_bus[31:0]\"\n",
    "print(f\"   Bus signal: '{bus_signal}'\")\n",
    "\n",
    "# Positive indexing (0-based)\n",
    "print(f\"   First char: bus_signal[0] = '{bus_signal[0]}'\")\n",
    "print(f\"   Fifth char: bus_signal[4] = '{bus_signal[4]}'\")\n",
    "print(f\"   Last char: bus_signal[{len(bus_signal)-1}] = '{bus_signal[len(bus_signal)-1]}'\")\n",
    "\n",
    "# Negative indexing (from end)\n",
    "print(f\"   Last char: bus_signal[-1] = '{bus_signal[-1]}'\")\n",
    "print(f\"   Second last: bus_signal[-2] = '{bus_signal[-2]}'\")\n",
    "\n",
    "# Slicing [start:end:step]\n",
    "print(f\"\\n   Slicing examples:\")\n",
    "print(f\"   First 4 chars: bus_signal[:4] = '{bus_signal[:4]}'\")\n",
    "print(f\"   Last 5 chars: bus_signal[-5:] = '{bus_signal[-5:]}'\")\n",
    "print(f\"   Middle section: bus_signal[5:8] = '{bus_signal[5:8]}'\")\n",
    "print(f\"   Every 2nd char: bus_signal[::2] = '{bus_signal[::2]}'\")\n",
    "print(f\"   Reverse string: bus_signal[::-1] = '{bus_signal[::-1]}'\")\n",
    "\n",
    "# Practical VLSI slicing\n",
    "hierarchy_path = \"cpu_core/alu_unit/adder_inst/carry_out\"\n",
    "print(f\"\\n   Hierarchy path: '{hierarchy_path}'\")\n",
    "print(f\"   Top module: '{hierarchy_path.split('/')[0]}'\")\n",
    "print(f\"   Signal name: '{hierarchy_path.split('/')[-1]}'\")\n",
    "print(f\"   Parent path: '{'/'.join(hierarchy_path.split('/')[:-1])}'\")\n",
    "\n",
    "# Extract bus width from signal name\n",
    "def extract_bus_width(signal_name):\n",
    "    \"\"\"Extract bus width from signal like 'data[31:0]'\"\"\"\n",
    "    if '[' in signal_name and ']' in signal_name:\n",
    "        start_bracket = signal_name.find('[')\n",
    "        end_bracket = signal_name.find(']')\n",
    "        bus_range = signal_name[start_bracket+1:end_bracket]\n",
    "        if ':' in bus_range:\n",
    "            msb, lsb = bus_range.split(':')\n",
    "            return int(msb) - int(lsb) + 1\n",
    "    return 1\n",
    "\n",
    "test_signals = [\"clk\", \"data[31:0]\", \"addr[15:0]\", \"ctrl[7:0]\", \"enable\"]\n",
    "print(f\"\\n   Bus width extraction:\")\n",
    "for signal in test_signals:\n",
    "    width = extract_bus_width(signal)\n",
    "    print(f\"     {signal:12} ‚Üí {width:2d} bits\")\n",
    "\n",
    "# =============================================================================\n",
    "# STRING ITERATION AND MEMBERSHIP\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüîÑ STRING ITERATION AND MEMBERSHIP:\")\n",
    "\n",
    "# Character iteration\n",
    "module_name = \"CPU_CORE\"\n",
    "print(f\"   Module name: '{module_name}'\")\n",
    "print(\"   Character iteration:\", end=\" \")\n",
    "for char in module_name:\n",
    "    print(f\"'{char}'\", end=\" \")\n",
    "print()\n",
    "\n",
    "# Membership testing\n",
    "test_chars = ['C', 'P', 'U', '_', 'x', '1']\n",
    "print(f\"   Membership testing in '{module_name}':\")\n",
    "for char in test_chars:\n",
    "    result = char in module_name\n",
    "    print(f\"     '{char}' in module_name: {result}\")\n",
    "\n",
    "# Substring membership\n",
    "test_substrings = [\"CPU\", \"CORE\", \"ALU\", \"_\", \"cpu\"]\n",
    "print(f\"\\n   Substring testing in '{module_name}':\")\n",
    "for substring in test_substrings:\n",
    "    result = substring in module_name\n",
    "    print(f\"     '{substring}' in module_name: {result}\")\n",
    "\n",
    "# Practical example: Check file extensions\n",
    "design_files = [\n",
    "    \"cpu_core.v\", \"cpu_core.sdc\", \"cpu_core.lib\",\n",
    "    \"memory.db\", \"io_ring.lef\", \"timing.rpt\"\n",
    "]\n",
    "\n",
    "valid_extensions = ['.v', '.sv', '.sdc', '.lib', '.db', '.lef']\n",
    "print(f\"\\n   File extension validation:\")\n",
    "for filename in design_files:\n",
    "    is_valid = any(filename.endswith(ext) for ext in valid_extensions)\n",
    "    status = \"‚úÖ\" if is_valid else \"‚ùå\"\n",
    "    print(f\"     {filename:15} {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86573aa",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è **Comprehensive String Methods for VLSI Automation**\n",
    "\n",
    "Python strings provide 25+ essential methods for VLSI automation. Master these for professional development:\n",
    "\n",
    "### **Search and Find Methods**\n",
    "- `.find(sub)` / `.rfind(sub)`: Find substring position (returns -1 if not found)\n",
    "- `.index(sub)` / `.rindex(sub)`: Find substring position (raises exception if not found)  \n",
    "- `.count(sub)`: Count non-overlapping occurrences\n",
    "- `.startswith(prefix)` / `.endswith(suffix)`: Check string boundaries\n",
    "\n",
    "### **Validation and Testing Methods**\n",
    "- `.isdigit()`, `.isalpha()`, `.isalnum()`: Character type validation\n",
    "- `.islower()`, `.isupper()`, `.istitle()`: Case checking\n",
    "- `.isspace()`, `.isdecimal()`, `.isnumeric()`: Specialized validation\n",
    "\n",
    "### **Case Conversion Methods**\n",
    "- `.upper()`, `.lower()`: Convert case\n",
    "- `.title()`, `.capitalize()`: Title and sentence case\n",
    "- `.swapcase()`: Invert case of all characters\n",
    "\n",
    "### **Cleaning and Trimming Methods**  \n",
    "- `.strip()`, `.lstrip()`, `.rstrip()`: Remove whitespace/characters\n",
    "- `.replace(old, new)`: Replace substrings\n",
    "- `.translate()`: Character-level translation\n",
    "\n",
    "### **Splitting and Joining Methods**\n",
    "- `.split(sep)`, `.rsplit(sep)`: Split string into list\n",
    "- `.partition(sep)`, `.rpartition(sep)`: Split into 3-tuple\n",
    "- `.join(iterable)`: Join sequence into string\n",
    "- `.splitlines()`: Split on line boundaries\n",
    "\n",
    "### **Formatting and Alignment Methods**\n",
    "- `.format()`: Template-based formatting\n",
    "- `.center(width)`, `.ljust(width)`, `.rjust(width)`: Text alignment  \n",
    "- `.zfill(width)`: Zero-pad numbers\n",
    "- `.expandtabs()`: Convert tabs to spaces\n",
    "\n",
    "**üí° Pro Tip**: Each method returns a new string (immutability). Chain operations efficiently: `text.strip().lower().replace('_', '')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace6dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPREHENSIVE STRING METHODS FOR VLSI AUTOMATION\n",
    "# =================================================\n",
    "# Master all essential string methods with VLSI examples\n",
    "\n",
    "print(\"üõ†Ô∏è COMPREHENSIVE STRING METHODS FOR VLSI AUTOMATION\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# =============================================================================\n",
    "# SEARCH AND FIND METHODS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüîç SEARCH AND FIND METHODS:\")\n",
    "\n",
    "# Sample timing violation log line\n",
    "log_line = \"ERROR: Setup violation on path cpu_core/reg_a to cpu_core/reg_b, slack = -0.123ns at corner ss_0p72v_125c\"\n",
    "\n",
    "print(f\"Log line: {log_line}\")\n",
    "print(f\"Length: {len(log_line)} characters\")\n",
    "\n",
    "# .find() vs .index() methods\n",
    "print(f\"\\n   find() vs index() comparison:\")\n",
    "print(f\"   log_line.find('ERROR'): {log_line.find('ERROR')}\")           # Returns position\n",
    "print(f\"   log_line.find('WARNING'): {log_line.find('WARNING')}\")       # Returns -1 if not found\n",
    "print(f\"   log_line.rfind('_'): {log_line.rfind('_')}\")                 # Find from right\n",
    "\n",
    "try:\n",
    "    print(f\"   log_line.index('ERROR'): {log_line.index('ERROR')}\")      # Returns position\n",
    "    print(f\"   log_line.index('WARNING'): \", end=\"\")\n",
    "    print(log_line.index('WARNING'))  # This will raise ValueError\n",
    "except ValueError as e:\n",
    "    print(f\"ValueError - {e}\")\n",
    "\n",
    "# .count() method\n",
    "print(f\"\\n   count() method examples:\")\n",
    "print(f\"   Underscores in path: log_line.count('_') = {log_line.count('_')}\")\n",
    "print(f\"   Letter 'r' count: log_line.count('r') = {log_line.count('r')}\")\n",
    "print(f\"   'reg' occurrences: log_line.count('reg') = {log_line.count('reg')}\")\n",
    "\n",
    "# .startswith() and .endswith() methods\n",
    "test_files = [\n",
    "    \"cpu_core.v\", \"memory_ctrl.sv\", \"io_ring.sdc\",\n",
    "    \"tech_lib.lib\", \"timing_report.txt\", \"layout.def\"\n",
    "]\n",
    "\n",
    "print(f\"\\n   File type classification:\")\n",
    "verilog_extensions = ('.v', '.sv')\n",
    "constraint_extensions = ('.sdc', '.upf')\n",
    "library_extensions = ('.lib', '.db')\n",
    "\n",
    "for filename in test_files:\n",
    "    if filename.endswith(verilog_extensions):\n",
    "        file_type = \"Verilog\"\n",
    "    elif filename.endswith(constraint_extensions):\n",
    "        file_type = \"Constraints\"\n",
    "    elif filename.endswith(library_extensions):\n",
    "        file_type = \"Library\"\n",
    "    else:\n",
    "        file_type = \"Other\"\n",
    "    print(f\"     {filename:18} ‚Üí {file_type}\")\n",
    "\n",
    "# =============================================================================\n",
    "# VALIDATION AND TESTING METHODS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n‚úÖ VALIDATION AND TESTING METHODS:\")\n",
    "\n",
    "# Signal name validation examples\n",
    "signal_names = [\n",
    "    \"clk\", \"reset_n\", \"data_in_32\", \"123invalid\",\n",
    "    \"VALID_SIGNAL\", \"signal-with-dash\", \"signal_with_space \", \"signal123\"\n",
    "]\n",
    "\n",
    "print(f\"   Signal name validation:\")\n",
    "print(f\"   {'Signal Name':<20} {'Alpha':<6} {'Alnum':<6} {'Digit':<6} {'Lower':<6} {'Upper':<6}\")\n",
    "print(f\"   {'-'*20:<20} {'-'*5:<6} {'-'*5:<6} {'-'*5:<6} {'-'*5:<6} {'-'*5:<6}\")\n",
    "\n",
    "for signal in signal_names:\n",
    "    clean_signal = signal.strip()  # Remove trailing spaces\n",
    "    # Remove bus notation for testing\n",
    "    base_signal = clean_signal.split('[')[0].replace('_', 'a')  # Replace _ for alpha test\n",
    "\n",
    "    print(f\"   {signal:<20} {base_signal.isalpha()!s:<6} {clean_signal.replace('_','').isalnum()!s:<6} \"\n",
    "          f\"{clean_signal.isdigit()!s:<6} {clean_signal.islower()!s:<6} {clean_signal.isupper()!s:<6}\")\n",
    "\n",
    "# Numeric validation for timing values\n",
    "timing_values = [\"10.5\", \"0.123\", \"-2.45\", \"1e-9\", \"invalid\", \"123\", \"\"]\n",
    "\n",
    "print(f\"\\n   Timing value validation:\")\n",
    "for value in timing_values:\n",
    "    is_decimal = value.replace('.', '').replace('-', '').replace('e', '').replace('+', '').isdigit() if value else False\n",
    "    is_numeric = value.replace('.', '').replace('-', '').isdigit() if value else False\n",
    "\n",
    "    try:\n",
    "        float_val = float(value) if value else None\n",
    "        is_convertible = True\n",
    "    except ValueError:\n",
    "        is_convertible = False\n",
    "        float_val = None\n",
    "\n",
    "    print(f\"     {value:<10} ‚Üí Numeric: {is_numeric!s:<5} Decimal: {is_decimal!s:<5} Convertible: {is_convertible!s:<5}\")\n",
    "\n",
    "# =============================================================================\n",
    "# CASE CONVERSION METHODS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüî§ CASE CONVERSION METHODS:\")\n",
    "\n",
    "# Module names from different sources\n",
    "module_names = [\"CPU_Core\", \"alu_unit\", \"MEMORY_CTRL\", \"io_Ring\", \"cache_L1\"]\n",
    "\n",
    "print(f\"   Module name standardization:\")\n",
    "print(f\"   {'Original':<12} {'lower()':<12} {'upper()':<12} {'title()':<12} {'capitalize()':<12} {'swapcase()':<12}\")\n",
    "print(f\"   {'-'*11:<12} {'-'*11:<12} {'-'*11:<12} {'-'*11:<12} {'-'*11:<12} {'-'*11:<12}\")\n",
    "\n",
    "for name in module_names:\n",
    "    print(f\"   {name:<12} {name.lower():<12} {name.upper():<12} {name.title():<12} \"\n",
    "          f\"{name.capitalize():<12} {name.swapcase():<12}\")\n",
    "\n",
    "# Corner name formatting\n",
    "corner_raw = \"ss_0p72v_125c\"\n",
    "print(f\"\\n   Corner name formatting:\")\n",
    "print(f\"   Raw corner: '{corner_raw}'\")\n",
    "print(f\"   Title case: '{corner_raw.title()}'\")\n",
    "print(f\"   Formatted:  '{corner_raw.replace('p', '.').replace('_', ' ').title()}'\")\n",
    "\n",
    "# =============================================================================\n",
    "# CLEANING AND TRIMMING METHODS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüßπ CLEANING AND TRIMMING METHODS:\")\n",
    "\n",
    "# Parse messy signal names from tool outputs\n",
    "messy_signals = [\n",
    "    \"  signal_name  \", \"\\tclk\\n\", \"reset_n\\r\\n\",\n",
    "    \"  data[31:0]  \\t\", \"enable   \", \"\\n\\n  addr_bus  \\n\"\n",
    "]\n",
    "\n",
    "print(f\"   Signal cleaning:\")\n",
    "for signal in messy_signals:\n",
    "    original_repr = repr(signal)\n",
    "    cleaned = signal.strip()\n",
    "    print(f\"     {original_repr:<20} ‚Üí '{cleaned}'\")\n",
    "\n",
    "# Character replacement for file path normalization\n",
    "file_paths = [\n",
    "    \"cpu-core/alu-unit\", \"memory ctrl/cache\", \"io ring\\\\layout\",\n",
    "    \"design@version2\", \"module#temp.v\"\n",
    "]\n",
    "\n",
    "print(f\"\\n   File path normalization:\")\n",
    "for path in file_paths:\n",
    "    # Replace problematic characters\n",
    "    normalized = (path.replace('-', '_')\n",
    "                      .replace(' ', '_')\n",
    "                      .replace('\\\\', '/')\n",
    "                      .replace('@', '_v')\n",
    "                      .replace('#', '_'))\n",
    "    print(f\"     '{path}' ‚Üí '{normalized}'\")\n",
    "\n",
    "# Advanced cleaning with .translate()\n",
    "print(f\"\\n   Advanced character removal with translate():\")\n",
    "signal_with_special = \"signal@#$%^&*()name_123\"\n",
    "# Create translation table to remove special characters\n",
    "import string\n",
    "remove_chars = \"!@#$%^&*()\"\n",
    "translator = str.maketrans('', '', remove_chars)\n",
    "cleaned_signal = signal_with_special.translate(translator)\n",
    "print(f\"     Original: '{signal_with_special}'\")\n",
    "print(f\"     Cleaned:  '{cleaned_signal}'\")\n",
    "\n",
    "# =============================================================================\n",
    "# SPLITTING AND JOINING METHODS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n‚úÇÔ∏è SPLITTING AND JOINING METHODS:\")\n",
    "\n",
    "# Hierarchical path processing\n",
    "hierarchy_path = \"cpu_core/alu_unit/adder_inst/sum_output\"\n",
    "\n",
    "print(f\"   Hierarchy path: '{hierarchy_path}'\")\n",
    "print(f\"   .split('/'):     {hierarchy_path.split('/')}\")\n",
    "print(f\"   .rsplit('/', 1): {hierarchy_path.rsplit('/', 1)}\")  # Split only once from right\n",
    "\n",
    "# .partition() vs .split() for simple splits\n",
    "signal_with_bus = \"data_bus[31:0]\"\n",
    "print(f\"\\n   Signal: '{signal_with_bus}'\")\n",
    "print(f\"   .partition('['):  {signal_with_bus.partition('[')}\")\n",
    "print(f\"   .rpartition('['): {signal_with_bus.rpartition('[')}\")\n",
    "\n",
    "# Multiple separators using replace + split\n",
    "mixed_separators = \"cpu_core.alu_unit/adder-inst\"\n",
    "print(f\"\\n   Mixed separators: '{mixed_separators}'\")\n",
    "normalized = mixed_separators.replace('.', '/').replace('-', '_')\n",
    "parts = normalized.split('/')\n",
    "print(f\"   Normalized and split: {parts}\")\n",
    "\n",
    "# .join() method for path reconstruction\n",
    "path_parts = [\"designs\", \"cpu_core\", \"implementation\", \"route\"]\n",
    "unix_path = \"/\".join(path_parts)\n",
    "windows_path = \"\\\\\".join(path_parts)\n",
    "dot_notation = \".\".join(path_parts)\n",
    "\n",
    "print(f\"\\n   Path reconstruction:\")\n",
    "print(f\"   Parts: {path_parts}\")\n",
    "print(f\"   Unix:    '{unix_path}'\")\n",
    "print(f\"   Windows: '{windows_path}'\")\n",
    "print(f\"   Dot:     '{dot_notation}'\")\n",
    "\n",
    "# .splitlines() for multi-line report processing\n",
    "timing_report_sample = \"\"\"Path 1: cpu_core/reg_a to cpu_core/reg_b\n",
    "slack (VIOLATED) -0.123\n",
    "Path 2: cpu_core/reg_c to cpu_core/reg_d\n",
    "slack (MET) 0.456\"\"\"\n",
    "\n",
    "print(f\"\\n   Report line processing:\")\n",
    "lines = timing_report_sample.splitlines()\n",
    "for i, line in enumerate(lines):\n",
    "    if line.strip():  # Skip empty lines\n",
    "        print(f\"     Line {i+1}: '{line.strip()}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e759c",
   "metadata": {},
   "source": [
    "## üìê **String Formatting and Alignment Methods**\n",
    "\n",
    "Professional VLSI reports require precise formatting and alignment:\n",
    "\n",
    "### **Template-Based Formatting**\n",
    "- **f-strings** (Python 3.6+): `f\"Design: {name}, Area: {area:.2f}¬µm¬≤\"`\n",
    "- **.format() method**: `\"Design: {}, Area: {:.2f}¬µm¬≤\".format(name, area)`\n",
    "- **% formatting**: `\"Design: %s, Area: %.2f ¬µm¬≤\" % (name, area)`\n",
    "\n",
    "### **Alignment and Padding Methods**\n",
    "- `.center(width, fillchar)`: Center text within specified width\n",
    "- `.ljust(width, fillchar)`: Left-justify text\n",
    "- `.rjust(width, fillchar)`: Right-justify text  \n",
    "- `.zfill(width)`: Zero-pad numbers from left\n",
    "\n",
    "### **Advanced Formatting**\n",
    "- `.expandtabs(tabsize)`: Convert tabs to spaces\n",
    "- Format specifications: `{:>10.2f}` (right-align, width 10, 2 decimals)\n",
    "- Thousands separators: `{:,}` for numbers like `1,234,567`\n",
    "\n",
    "### **VLSI Report Formatting Applications**\n",
    "- **Timing Reports**: Align path delays and slack values\n",
    "- **Area Reports**: Format instance counts and areas\n",
    "- **Power Reports**: Display power consumption with units\n",
    "- **Pin Maps**: Create structured signal listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b498a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRING FORMATTING AND ALIGNMENT FOR PROFESSIONAL REPORTS\n",
    "# =========================================================\n",
    "# Master formatting methods for high-quality VLSI reports\n",
    "\n",
    "print(\"üìê STRING FORMATTING AND ALIGNMENT FOR PROFESSIONAL REPORTS\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# =============================================================================\n",
    "# TEMPLATE-BASED FORMATTING METHODS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìã TEMPLATE-BASED FORMATTING METHODS:\")\n",
    "\n",
    "# Design data for formatting examples\n",
    "design_data = {\n",
    "    'name': 'cpu_core',\n",
    "    'instances': 125000,\n",
    "    'area': 1250.45,\n",
    "    'power': 0.0825,\n",
    "    'frequency': 1000.0,\n",
    "    'corners': ['ss_0p72v_125c', 'tt_0p8v_25c', 'ff_0p88v_m40c']\n",
    "}\n",
    "\n",
    "# Method 1: f-strings (Python 3.6+) - Recommended\n",
    "print(\"   f-string formatting (Python 3.6+):\")\n",
    "area_report_f = f\"Design: {design_data['name']}, Instances: {design_data['instances']:,}, Area: {design_data['area']:.2f}¬µm¬≤\"\n",
    "power_report_f = f\"Power: {design_data['power']:.4f}W @ {design_data['frequency']:.1f}MHz\"\n",
    "print(f\"     {area_report_f}\")\n",
    "print(f\"     {power_report_f}\")\n",
    "\n",
    "# Method 2: .format() method - Universal compatibility\n",
    "print(\"\\n   .format() method:\")\n",
    "area_report_fmt = \"Design: {name}, Instances: {instances:,}, Area: {area:.2f}¬µm¬≤\".format(**design_data)\n",
    "power_report_fmt = \"Power: {power:.4f}W @ {frequency:.1f}MHz\".format(**design_data)\n",
    "print(f\"     {area_report_fmt}\")\n",
    "print(f\"     {power_report_fmt}\")\n",
    "\n",
    "# Method 3: % formatting - Legacy but still used\n",
    "print(\"\\n   % formatting (legacy):\")\n",
    "area_report_pct = \"Design: %s, Instances: %s, Area: %.2f¬µm¬≤\" % (\n",
    "    design_data['name'], f\"{design_data['instances']:,}\", design_data['area']\n",
    ")\n",
    "print(f\"     {area_report_pct}\")\n",
    "\n",
    "# Advanced f-string formatting\n",
    "print(\"\\n   Advanced f-string formatting:\")\n",
    "for corner in design_data['corners']:\n",
    "    # Extract voltage and temperature from corner name\n",
    "    parts = corner.split('_')\n",
    "    voltage = parts[1].replace('p', '.')\n",
    "    temp = parts[2].replace('c', '')\n",
    "\n",
    "    formatted_corner = f\"{corner:>15} ‚Üí Voltage: {voltage:>5}V, Temperature: {temp:>4}¬∞C\"\n",
    "    print(f\"     {formatted_corner}\")\n",
    "\n",
    "# =============================================================================\n",
    "# ALIGNMENT AND PADDING METHODS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüìè ALIGNMENT AND PADDING METHODS:\")\n",
    "\n",
    "# Sample timing paths for report formatting\n",
    "timing_paths = [\n",
    "    {'path': 'cpu_core/reg_a', 'slack': -0.123, 'delay': 2.45},\n",
    "    {'path': 'cpu_core/reg_b', 'slack': 0.456, 'delay': 1.23},\n",
    "    {'path': 'memory_ctrl/reg_c', 'slack': -0.089, 'delay': 3.78},\n",
    "    {'path': 'io_ring/reg_d', 'slack': 0.234, 'delay': 0.95}\n",
    "]\n",
    "\n",
    "# Create aligned timing report\n",
    "print(\"   Aligned timing report:\")\n",
    "print(\"     \" + \"Path Name\".ljust(20) + \"Slack\".rjust(10) + \"Delay\".rjust(10))\n",
    "print(\"     \" + \"-\" * 20 + \"-\" * 10 + \"-\" * 10)\n",
    "\n",
    "for path_data in timing_paths:\n",
    "    path_name = path_data['path'].ljust(20)\n",
    "    slack_str = f\"{path_data['slack']:+.3f}\".rjust(10)\n",
    "    delay_str = f\"{path_data['delay']:.3f}\".rjust(10)\n",
    "    print(f\"     {path_name}{slack_str}{delay_str}\")\n",
    "\n",
    "# .center(), .ljust(), .rjust() demonstrations\n",
    "print(f\"\\n   Text alignment examples:\")\n",
    "module_name = \"CPU_CORE\"\n",
    "print(f\"     Original: '{module_name}'\")\n",
    "print(f\"     .center(20, '-'): '{module_name.center(20, '-')}'\")\n",
    "print(f\"     .ljust(20, '.'): '{module_name.ljust(20, '.')}'\")\n",
    "print(f\"     .rjust(20, '*'): '{module_name.rjust(20, '*')}'\")\n",
    "\n",
    "# .zfill() for instance numbering\n",
    "print(f\"\\n   Instance numbering with .zfill():\")\n",
    "instance_numbers = [1, 25, 456, 7890, 12345]\n",
    "for num in instance_numbers:\n",
    "    padded = str(num).zfill(6)\n",
    "    instance_name = f\"inst_{padded}\"\n",
    "    print(f\"     {num:5d} ‚Üí '{instance_name}'\")\n",
    "\n",
    "# =============================================================================\n",
    "# ADVANCED FORMATTING SPECIFICATIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüéØ ADVANCED FORMATTING SPECIFICATIONS:\")\n",
    "\n",
    "# Format specification syntax: {[field_name]:[format_spec]}\n",
    "# format_spec: [[fill]align][sign][#][0][width][,][.precision][type]\n",
    "\n",
    "metrics_data = [\n",
    "    {'metric': 'Area', 'value': 1250.456789, 'unit': '¬µm¬≤'},\n",
    "    {'metric': 'Power', 'value': 0.082567, 'unit': 'W'},\n",
    "    {'metric': 'Frequency', 'value': 1000.0, 'unit': 'MHz'},\n",
    "    {'metric': 'Instances', 'value': 125000, 'unit': 'count'}\n",
    "]\n",
    "\n",
    "print(\"   Advanced format specifications:\")\n",
    "print(\"     \" + \"Metric\".ljust(12) + \"Value\".rjust(15) + \"Unit\".rjust(8))\n",
    "print(\"     \" + \"-\" * 12 + \"-\" * 15 + \"-\" * 8)\n",
    "\n",
    "for data in metrics_data:\n",
    "    metric = data['metric'].ljust(12)\n",
    "\n",
    "    # Different format specifications based on data type\n",
    "    if data['metric'] == 'Instances':\n",
    "        value = f\"{data['value']:>12,}\"  # Thousands separator\n",
    "    elif data['metric'] == 'Frequency':\n",
    "        value = f\"{data['value']:>12.1f}\"  # 1 decimal place\n",
    "    else:\n",
    "        value = f\"{data['value']:>12.6f}\"  # 6 decimal places\n",
    "\n",
    "    unit = data['unit'].rjust(8)\n",
    "    print(f\"     {metric}{value}{unit}\")\n",
    "\n",
    "# Binary and hex formatting for register values\n",
    "print(f\"\\n   Number base formatting:\")\n",
    "register_values = [255, 1024, 65535, 4095]\n",
    "print(\"     \" + \"Decimal\".rjust(8) + \"Binary\".rjust(20) + \"Hex\".rjust(8))\n",
    "print(\"     \" + \"-\" * 8 + \"-\" * 20 + \"-\" * 8)\n",
    "\n",
    "for value in register_values:\n",
    "    decimal = f\"{value:>8d}\"\n",
    "    binary = f\"{value:>20b}\"\n",
    "    hexadecimal = f\"{value:>8X}\"\n",
    "    print(f\"     {decimal}{binary}{hexadecimal}\")\n",
    "\n",
    "# =============================================================================\n",
    "# MULTI-LINE STRING FORMATTING\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüìÑ MULTI-LINE STRING FORMATTING:\")\n",
    "\n",
    "# Create a formatted SDC constraint file\n",
    "sdc_template = \"\"\"\n",
    "# SDC Constraints for {design_name}\n",
    "# Generated automatically for {technology} technology\n",
    "\n",
    "# Clock Definition\n",
    "create_clock -period {period:.2f} -name {clock_name} [get_ports {clock_port}]\n",
    "set_clock_uncertainty {uncertainty:.3f} [get_clocks {clock_name}]\n",
    "\n",
    "# Input/Output Delays\n",
    "set_input_delay {input_delay:.2f} -clock {clock_name} [all_inputs]\n",
    "set_output_delay {output_delay:.2f} -clock {clock_name} [all_outputs]\n",
    "\n",
    "# Operating Conditions\n",
    "set_operating_conditions {corner}\n",
    "set_voltage {voltage:.2f} [get_ports VDD]\n",
    "set_temperature {temperature}\n",
    "\n",
    "# Load and Drive Strength\n",
    "set_load {load_cap:.3f} [all_outputs]\n",
    "set_driving_cell -lib_cell {drive_cell} [all_inputs]\n",
    "\"\"\".strip()\n",
    "\n",
    "# Format the template with actual values\n",
    "sdc_content = sdc_template.format(\n",
    "    design_name=\"cpu_core\",\n",
    "    technology=\"TSMC28\",\n",
    "    period=10.0,\n",
    "    clock_name=\"clk\",\n",
    "    clock_port=\"clk\",\n",
    "    uncertainty=0.1,\n",
    "    input_delay=2.0,\n",
    "    output_delay=1.5,\n",
    "    corner=\"ss_0p72v_125c\",\n",
    "    voltage=0.72,\n",
    "    temperature=125,\n",
    "    load_cap=0.01,\n",
    "    drive_cell=\"BUFX4\"\n",
    ")\n",
    "\n",
    "print(\"   Generated SDC file:\")\n",
    "print(\"   \" + \"\\n   \".join(sdc_content.split('\\n')[:10]))  # Show first 10 lines\n",
    "print(\"   ... (truncated)\")\n",
    "\n",
    "# Table formatting for pin mapping\n",
    "print(f\"\\n   Pin mapping table:\")\n",
    "pin_data = [\n",
    "    ('clk', 'input', 1, 'A1'),\n",
    "    ('reset_n', 'input', 1, 'A2'),\n",
    "    ('data_in', 'input', 32, 'B1-B32'),\n",
    "    ('data_out', 'output', 32, 'C1-C32'),\n",
    "    ('valid', 'output', 1, 'D1')\n",
    "]\n",
    "\n",
    "# Create formatted table\n",
    "header = f\"{'Pin Name':<12} {'Direction':<10} {'Width':<6} {'Location':<10}\"\n",
    "separator = \"-\" * len(header)\n",
    "print(f\"     {header}\")\n",
    "print(f\"     {separator}\")\n",
    "\n",
    "for pin_name, direction, width, location in pin_data:\n",
    "    row = f\"{pin_name:<12} {direction:<10} {width:<6} {location:<10}\"\n",
    "    print(f\"     {row}\")\n",
    "\n",
    "print(f\"\\nüèÜ STRING FORMATTING BENEFITS:\")\n",
    "print(\"‚úÖ **Professional Reports**: Clean, aligned output for presentations\")\n",
    "print(\"‚úÖ **Automated Scripts**: Template-based file generation\")\n",
    "print(\"‚úÖ **Data Visualization**: Structured display of metrics and results\")\n",
    "print(\"‚úÖ **Documentation**: Consistent formatting across all outputs\")\n",
    "print(\"‚úÖ **Debugging**: Clear formatting aids in troubleshooting\")\n",
    "print(\"‚úÖ **Standards Compliance**: Meet industry formatting requirements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f317f6",
   "metadata": {},
   "source": [
    "## üöÄ **Advanced String Operations and Performance**\n",
    "\n",
    "Professional VLSI automation demands sophisticated string handling:\n",
    "\n",
    "### **Regular Expressions for Complex Parsing**\n",
    "- **Pattern Matching**: Extract data from timing reports, netlists, and logs\n",
    "- **Validation**: Verify signal names, file formats, and constraint syntax\n",
    "- **Substitution**: Bulk text replacements in large design files\n",
    "\n",
    "### **Performance Optimization Techniques**\n",
    "- **Efficient Concatenation**: Use `.join()` instead of `+=` for large datasets\n",
    "- **Memory Management**: Stream processing for multi-gigabyte files\n",
    "- **Caching**: Store frequently used string operations\n",
    "- **Generator Functions**: Process large files without loading into memory\n",
    "\n",
    "### **Professional Error Handling**\n",
    "- **Input Validation**: Sanitize user inputs and file paths\n",
    "- **Encoding Handling**: Support UTF-8 for international teams\n",
    "- **Fallback Strategies**: Graceful handling of malformed data\n",
    "- **Security**: Prevent injection attacks in generated scripts\n",
    "\n",
    "### **Real-World Applications**\n",
    "- **Tool Integration**: Parse outputs from 20+ EDA tools\n",
    "- **Report Generation**: Create professional documentation\n",
    "- **Script Automation**: Generate TCL/Python/Shell scripts\n",
    "- **Database Processing**: Handle millions of design objects efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f579c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADVANCED STRING OPERATIONS AND PROFESSIONAL TECHNIQUES\n",
    "# =======================================================\n",
    "# Pattern matching, performance optimization, and production-ready code\n",
    "\n",
    "print(\"üöÄ ADVANCED STRING OPERATIONS AND PROFESSIONAL TECHNIQUES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# =============================================================================\n",
    "# REGULAR EXPRESSIONS FOR COMPLEX PARSING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüéØ REGULAR EXPRESSIONS FOR COMPLEX PARSING:\")\n",
    "\n",
    "import re\n",
    "import time\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "# Complex timing report parsing with regex\n",
    "timing_report_complex = \"\"\"\n",
    "Information: Timing report generated at Thu Sep 05 14:30:25 2025\n",
    "Design: cpu_core\n",
    "Technology: tsmc28nm_hpc\n",
    "Corner: ss_0p72v_125c\n",
    "\n",
    "Startpoint: cpu_core/alu_unit/reg_a (rising edge-triggered flip-flop clocked by clk)\n",
    "Endpoint: cpu_core/mem_unit/reg_b (rising edge-triggered flip-flop clocked by clk)\n",
    "Path Group: clk\n",
    "Path Type: max\n",
    "\n",
    "  Point                                    Incr       Path\n",
    "  --------------------------------------------------------\n",
    "  clock clk (rise edge)                    0.00       0.00\n",
    "  clock network delay (ideal)              0.15       0.15\n",
    "  cpu_core/alu_unit/reg_a/CK (DFFX1)       0.00       0.15 r\n",
    "  cpu_core/alu_unit/reg_a/Q (DFFX1)        0.45       0.60 f\n",
    "  cpu_core/alu_unit/add_inst/sum[0] (ADD32) 0.85     1.45 f\n",
    "  cpu_core/mem_unit/reg_b/D (DFFX1)        0.05       1.50 f\n",
    "  data arrival time                                   1.50\n",
    "\n",
    "  clock clk (rise edge)                   10.00      10.00\n",
    "  clock network delay (ideal)              0.15      10.15\n",
    "  cpu_core/mem_unit/reg_b/CK (DFFX1)       0.00      10.15 r\n",
    "  library setup time                      -0.25       9.90\n",
    "  data required time                                  9.90\n",
    "  --------------------------------------------------------\n",
    "  data required time                                  9.90\n",
    "  data arrival time                                  -1.50\n",
    "  --------------------------------------------------------\n",
    "  slack (VIOLATED)                                    -0.60\n",
    "\"\"\"\n",
    "\n",
    "class TimingReportParser:\n",
    "    \"\"\"Professional timing report parser using regex\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Compile regex patterns for efficiency\n",
    "        self.patterns = {\n",
    "            'header_info': re.compile(r'^(\\w+):\\s+(.+)$', re.MULTILINE),\n",
    "            'startpoint': re.compile(r'Startpoint:\\s+([^\\s]+)'),\n",
    "            'endpoint': re.compile(r'Endpoint:\\s+([^\\s]+)'),\n",
    "            'slack': re.compile(r'slack\\s+\\(([^)]+)\\)\\s+([-+]?\\d*\\.?\\d+)'),\n",
    "            'path_point': re.compile(r'^\\s*([^()]+)\\s+\\(([^)]+)\\)\\s+([-+]?\\d*\\.?\\d+)\\s+([-+]?\\d*\\.?\\d+)\\s*([rf]?)$', re.MULTILINE),\n",
    "            'clock_period': re.compile(r'clock\\s+(\\w+)\\s+\\(rise edge\\)\\s+([-+]?\\d*\\.?\\d+)'),\n",
    "            'library_cell': re.compile(r'/([A-Z0-9_]+)\\)'),\n",
    "        }\n",
    "\n",
    "    def parse_report(self, report_text: str) -> Dict:\n",
    "        \"\"\"Parse timing report and extract all relevant information\"\"\"\n",
    "        result = {\n",
    "            'header': {},\n",
    "            'startpoint': None,\n",
    "            'endpoint': None,\n",
    "            'slack_status': None,\n",
    "            'slack_value': None,\n",
    "            'path_points': [],\n",
    "            'clock_period': None,\n",
    "            'violations': []\n",
    "        }\n",
    "\n",
    "        # Parse header information\n",
    "        for match in self.patterns['header_info'].finditer(report_text):\n",
    "            key = match.group(1).lower()\n",
    "            value = match.group(2).strip()\n",
    "            result['header'][key] = value\n",
    "\n",
    "        # Parse startpoint and endpoint\n",
    "        start_match = self.patterns['startpoint'].search(report_text)\n",
    "        if start_match:\n",
    "            result['startpoint'] = start_match.group(1)\n",
    "\n",
    "        end_match = self.patterns['endpoint'].search(report_text)\n",
    "        if end_match:\n",
    "            result['endpoint'] = end_match.group(1)\n",
    "\n",
    "        # Parse slack information\n",
    "        slack_match = self.patterns['slack'].search(report_text)\n",
    "        if slack_match:\n",
    "            result['slack_status'] = slack_match.group(1)\n",
    "            result['slack_value'] = float(slack_match.group(2))\n",
    "\n",
    "        # Parse clock period\n",
    "        clock_match = self.patterns['clock_period'].search(report_text)\n",
    "        if clock_match:\n",
    "            result['clock_period'] = float(clock_match.group(2))\n",
    "\n",
    "        # Parse path points (simplified for demonstration)\n",
    "        path_matches = self.patterns['path_point'].finditer(report_text)\n",
    "        for match in path_matches:\n",
    "            point_info = {\n",
    "                'instance': match.group(1).strip(),\n",
    "                'cell_type': match.group(2),\n",
    "                'incremental_delay': float(match.group(3)),\n",
    "                'path_delay': float(match.group(4)),\n",
    "                'transition': match.group(5) if match.group(5) else 'n/a'\n",
    "            }\n",
    "            result['path_points'].append(point_info)\n",
    "\n",
    "        return result\n",
    "\n",
    "# Demonstrate advanced parsing\n",
    "parser = TimingReportParser()\n",
    "parsed_data = parser.parse_report(timing_report_complex)\n",
    "\n",
    "print(\"   Parsed timing report:\")\n",
    "print(f\"     Design: {parsed_data['header'].get('design', 'Unknown')}\")\n",
    "print(f\"     Technology: {parsed_data['header'].get('technology', 'Unknown')}\")\n",
    "print(f\"     Corner: {parsed_data['header'].get('corner', 'Unknown')}\")\n",
    "print(f\"     Startpoint: {parsed_data['startpoint']}\")\n",
    "print(f\"     Endpoint: {parsed_data['endpoint']}\")\n",
    "print(f\"     Slack: {parsed_data['slack_value']:.3f}ns ({parsed_data['slack_status']})\")\n",
    "print(f\"     Path points: {len(parsed_data['path_points'])}\")\n",
    "\n",
    "# Signal name validation with complex regex\n",
    "print(f\"\\n   Advanced signal validation:\")\n",
    "signal_validation_pattern = re.compile(r'^[a-zA-Z_][a-zA-Z0-9_]*(?:\\[[0-9]+(?::[0-9]+)?\\])?$')\n",
    "\n",
    "test_signals = [\n",
    "    \"clk\", \"reset_n\", \"data_bus[31:0]\", \"addr[15]\",\n",
    "    \"123invalid\", \"valid_signal_name\", \"signal-invalid\", \"signal[invalid]\"\n",
    "]\n",
    "\n",
    "for signal in test_signals:\n",
    "    is_valid = bool(signal_validation_pattern.match(signal))\n",
    "    status = \"‚úÖ\" if is_valid else \"‚ùå\"\n",
    "    print(f\"     {signal:<20} {status}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PERFORMANCE OPTIMIZATION TECHNIQUES\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n‚ö° PERFORMANCE OPTIMIZATION TECHNIQUES:\")\n",
    "\n",
    "# Benchmark different concatenation methods\n",
    "def benchmark_string_operations():\n",
    "    \"\"\"Comprehensive string performance benchmarks\"\"\"\n",
    "    results = {}\n",
    "    test_sizes = [100, 1000, 10000]\n",
    "\n",
    "    for size in test_sizes:\n",
    "        test_data = [f\"instance_{i:06d}\" for i in range(size)]\n",
    "\n",
    "        # Method 1: += operator (inefficient)\n",
    "        start_time = time.perf_counter()\n",
    "        result1 = \"\"\n",
    "        for item in test_data:\n",
    "            result1 += item + \"\\n\"\n",
    "        time1 = time.perf_counter() - start_time\n",
    "\n",
    "        # Method 2: join() method (efficient)\n",
    "        start_time = time.perf_counter()\n",
    "        result2 = \"\\n\".join(test_data) + \"\\n\"\n",
    "        time2 = time.perf_counter() - start_time\n",
    "\n",
    "        # Method 3: List comprehension + join (most efficient)\n",
    "        start_time = time.perf_counter()\n",
    "        result3 = \"\\n\".join([item for item in test_data]) + \"\\n\"\n",
    "        time3 = time.perf_counter() - start_time\n",
    "\n",
    "        # Method 4: Generator + join (memory efficient)\n",
    "        start_time = time.perf_counter()\n",
    "        result4 = \"\\n\".join(item for item in test_data) + \"\\n\"\n",
    "        time4 = time.perf_counter() - start_time\n",
    "\n",
    "        results[size] = {\n",
    "            'plus_equals': time1,\n",
    "            'join': time2,\n",
    "            'list_join': time3,\n",
    "            'generator_join': time4\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "performance_results = benchmark_string_operations()\n",
    "\n",
    "print(\"   String concatenation performance comparison:\")\n",
    "print(\"     \" + \"Size\".ljust(8) + \"+= Method\".rjust(12) + \"join()\".rjust(12) +\n",
    "      \"list+join\".rjust(12) + \"gen+join\".rjust(12) + \"Speedup\".rjust(10))\n",
    "print(\"     \" + \"-\" * 8 + \"-\" * 12 + \"-\" * 12 + \"-\" * 12 + \"-\" * 12 + \"-\" * 10)\n",
    "\n",
    "for size, times in performance_results.items():\n",
    "    speedup = times['plus_equals'] / times['join']\n",
    "    row = (f\"{size:<8} {times['plus_equals']:>11.6f} {times['join']:>11.6f} \"\n",
    "           f\"{times['list_join']:>11.6f} {times['generator_join']:>11.6f} {speedup:>9.1f}x\")\n",
    "    print(f\"     {row}\")\n",
    "\n",
    "# Memory-efficient large file processing\n",
    "def process_large_design_file_simulation(num_instances: int = 100000):\n",
    "    \"\"\"Simulate memory-efficient processing of large design files\"\"\"\n",
    "\n",
    "    def generate_netlist_content():\n",
    "        \"\"\"Generator function for memory-efficient processing\"\"\"\n",
    "        yield \"// Auto-generated netlist\"\n",
    "        yield f\"module large_design();\"\n",
    "\n",
    "        for i in range(num_instances):\n",
    "            yield f\"  NAND2X1 inst_{i:06d} (.A(net_{i}), .B(enable), .Y(out_{i}));\"\n",
    "            if i % 10000 == 0 and i > 0:\n",
    "                yield f\"  // Processed {i:,} instances\"\n",
    "\n",
    "        yield \"endmodule\"\n",
    "\n",
    "    # Process without loading entire content into memory\n",
    "    start_time = time.perf_counter()\n",
    "    line_count = 0\n",
    "    instance_count = 0\n",
    "\n",
    "    for line in generate_netlist_content():\n",
    "        line_count += 1\n",
    "        if \"NAND2X1\" in line:\n",
    "            instance_count += 1\n",
    "\n",
    "    process_time = time.perf_counter() - start_time\n",
    "\n",
    "    return {\n",
    "        'lines_processed': line_count,\n",
    "        'instances_found': instance_count,\n",
    "        'processing_time': process_time,\n",
    "        'memory_efficient': True\n",
    "    }\n",
    "\n",
    "# Demonstrate large file processing\n",
    "large_file_stats = process_large_design_file_simulation(50000)\n",
    "print(f\"\\n   Large design file processing:\")\n",
    "print(f\"     Lines processed: {large_file_stats['lines_processed']:,}\")\n",
    "print(f\"     Instances found: {large_file_stats['instances_found']:,}\")\n",
    "print(f\"     Processing time: {large_file_stats['processing_time']:.3f} seconds\")\n",
    "print(f\"     Memory efficient: {large_file_stats['memory_efficient']}\")\n",
    "print(f\"     Rate: {large_file_stats['lines_processed']/large_file_stats['processing_time']:,.0f} lines/sec\")\n",
    "\n",
    "# =============================================================================\n",
    "# PROFESSIONAL ERROR HANDLING AND VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüõ°Ô∏è PROFESSIONAL ERROR HANDLING AND VALIDATION:\")\n",
    "\n",
    "class VLSIStringProcessor:\n",
    "    \"\"\"Production-ready string processor with comprehensive error handling\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_design_hierarchy(hierarchy_path: str) -> Tuple[bool, str, List[str]]:\n",
    "        \"\"\"Validate and parse design hierarchy path\"\"\"\n",
    "        if not isinstance(hierarchy_path, str):\n",
    "            return False, f\"Path must be string, got {type(hierarchy_path).__name__}\", []\n",
    "\n",
    "        if not hierarchy_path.strip():\n",
    "            return False, \"Path cannot be empty\", []\n",
    "\n",
    "        # Clean and validate path\n",
    "        clean_path = hierarchy_path.strip()\n",
    "\n",
    "        # Check for invalid characters\n",
    "        invalid_chars = set(clean_path) - set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_/')\n",
    "        if invalid_chars:\n",
    "            return False, f\"Invalid characters found: {invalid_chars}\", []\n",
    "\n",
    "        # Split and validate each level\n",
    "        levels = clean_path.split('/')\n",
    "        for level in levels:\n",
    "            if not level:\n",
    "                return False, \"Empty hierarchy level found\", []\n",
    "            if level[0].isdigit():\n",
    "                return False, f\"Hierarchy level '{level}' cannot start with digit\", []\n",
    "            if not level.replace('_', '').isalnum():\n",
    "                return False, f\"Hierarchy level '{level}' contains invalid characters\", []\n",
    "\n",
    "        return True, \"Valid hierarchy path\", levels\n",
    "\n",
    "    @staticmethod\n",
    "    def safe_float_conversion(value_str: str, default: float = 0.0) -> Tuple[float, bool, str]:\n",
    "        \"\"\"Safely convert string to float with error handling\"\"\"\n",
    "        if not isinstance(value_str, str):\n",
    "            return default, False, f\"Input must be string, got {type(value_str).__name__}\"\n",
    "\n",
    "        clean_value = value_str.strip()\n",
    "        if not clean_value:\n",
    "            return default, False, \"Empty string cannot be converted to float\"\n",
    "\n",
    "        try:\n",
    "            result = float(clean_value)\n",
    "            return result, True, \"Successful conversion\"\n",
    "        except ValueError:\n",
    "            # Try to handle common formatting issues\n",
    "            try:\n",
    "                # Remove common non-numeric suffixes\n",
    "                for suffix in ['ns', 'ps', 'ms', 'us', 'MHz', 'GHz', 'V', 'mV']:\n",
    "                    if clean_value.endswith(suffix):\n",
    "                        clean_value = clean_value[:-len(suffix)].strip()\n",
    "                        break\n",
    "\n",
    "                result = float(clean_value)\n",
    "                return result, True, f\"Converted after removing suffix\"\n",
    "            except ValueError:\n",
    "                return default, False, f\"Cannot convert '{value_str}' to float\"\n",
    "\n",
    "    @staticmethod\n",
    "    def sanitize_filename(filename: str, max_length: int = 255) -> str:\n",
    "        \"\"\"Sanitize filename for cross-platform compatibility\"\"\"\n",
    "        if not isinstance(filename, str):\n",
    "            raise TypeError(f\"Filename must be string, got {type(filename).__name__}\")\n",
    "\n",
    "        # Remove problematic characters\n",
    "        invalid_chars = '<>:\"/\\\\|?*'\n",
    "        clean_name = filename\n",
    "        for char in invalid_chars:\n",
    "            clean_name = clean_name.replace(char, '_')\n",
    "\n",
    "        # Remove control characters\n",
    "        clean_name = ''.join(char for char in clean_name if ord(char) >= 32)\n",
    "\n",
    "        # Trim whitespace and dots\n",
    "        clean_name = clean_name.strip('. ')\n",
    "\n",
    "        # Ensure reasonable length\n",
    "        if len(clean_name) > max_length:\n",
    "            name_part, ext = clean_name.rsplit('.', 1) if '.' in clean_name else (clean_name, '')\n",
    "            available_length = max_length - len(ext) - 1 if ext else max_length\n",
    "            clean_name = name_part[:available_length] + ('.' + ext if ext else '')\n",
    "\n",
    "        # Ensure not empty\n",
    "        if not clean_name:\n",
    "            clean_name = \"untitled\"\n",
    "\n",
    "        return clean_name\n",
    "\n",
    "# Test professional validation\n",
    "processor = VLSIStringProcessor()\n",
    "\n",
    "print(\"   Hierarchy validation:\")\n",
    "test_hierarchies = [\n",
    "    \"cpu_core/alu_unit/adder_inst\",\n",
    "    \"cpu_core//empty_level\",\n",
    "    \"123invalid/start_with_digit\",\n",
    "    \"valid_path/with_underscores\",\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "for hierarchy in test_hierarchies:\n",
    "    valid, message, levels = processor.validate_design_hierarchy(hierarchy)\n",
    "    status = \"‚úÖ\" if valid else \"‚ùå\"\n",
    "    print(f\"     {hierarchy:<30} {status} {message}\")\n",
    "\n",
    "print(f\"\\n   Safe float conversion:\")\n",
    "test_values = [\"10.5\", \"0.123ns\", \"-2.45V\", \"invalid\", \"\", \"1e-9\", \"100MHz\"]\n",
    "\n",
    "for value in test_values:\n",
    "    result, success, message = processor.safe_float_conversion(value)\n",
    "    status = \"‚úÖ\" if success else \"‚ùå\"\n",
    "    print(f\"     {value:<10} ‚Üí {result:8.3f} {status} {message}\")\n",
    "\n",
    "print(f\"\\n   Filename sanitization:\")\n",
    "test_filenames = [\n",
    "    \"design<>file.v\", \"path/with/slashes.sdc\", \"file:with:colons.lib\",\n",
    "    \"very_long_filename_that_exceeds_normal_limits_and_should_be_truncated.v\",\n",
    "    \"   file_with_spaces   .txt\"\n",
    "]\n",
    "\n",
    "for filename in test_filenames:\n",
    "    sanitized = processor.sanitize_filename(filename)\n",
    "    print(f\"     '{filename}' ‚Üí '{sanitized}'\")\n",
    "\n",
    "print(f\"\\nüèÜ ADVANCED STRING OPERATION BENEFITS:\")\n",
    "print(\"‚úÖ **Pattern Matching**: Extract complex data from any tool output\")\n",
    "print(\"‚úÖ **Performance**: Handle multi-gigabyte files efficiently\")\n",
    "print(\"‚úÖ **Error Handling**: Robust validation prevents script failures\")\n",
    "print(\"‚úÖ **Memory Efficiency**: Process large datasets without memory issues\")\n",
    "print(\"‚úÖ **Professional Quality**: Production-ready code with comprehensive testing\")\n",
    "print(\"‚úÖ **Cross-Platform**: Compatible filename and path handling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d89ce3",
   "metadata": {},
   "source": [
    "## üí™ **Practice Exercises: String Mastery for VLSI**\n",
    "\n",
    "Test your string manipulation skills with these hands-on VLSI exercises:\n",
    "\n",
    "### **üéØ Exercise 1: Signal Name Parser**\n",
    "Write a function that parses signal names and extracts:\n",
    "- Base name (e.g., \"data_bus\" from \"data_bus[31:0]\")\n",
    "- Bus width (e.g., 32 from \"data_bus[31:0]\")  \n",
    "- MSB and LSB indices\n",
    "- Whether it's a single bit or bus\n",
    "\n",
    "**Test Cases:**\n",
    "```python\n",
    "parse_signal(\"clk\")           # ‚Üí base=\"clk\", width=1, msb=None, lsb=None\n",
    "parse_signal(\"data[31:0]\")    # ‚Üí base=\"data\", width=32, msb=31, lsb=0\n",
    "parse_signal(\"addr[15:0]\")    # ‚Üí base=\"addr\", width=16, msb=15, lsb=0\n",
    "```\n",
    "\n",
    "### **üéØ Exercise 2: Timing Report Extractor**\n",
    "Create a function that extracts timing violations from a report string:\n",
    "- Find all paths with negative slack\n",
    "- Extract startpoint, endpoint, and slack value\n",
    "- Count total violations and worst slack\n",
    "\n",
    "### **üéØ Exercise 3: File Path Normalizer**\n",
    "Build a robust file path normalizer that:\n",
    "- Converts Windows paths to Unix format\n",
    "- Handles relative paths (../, ./)\n",
    "- Validates file extensions\n",
    "- Creates backup filenames with timestamps\n",
    "\n",
    "### **üéØ Exercise 4: TCL Script Generator**\n",
    "Write a template-based TCL script generator for:\n",
    "- Clock definitions with period and uncertainty\n",
    "- Input/output delay constraints\n",
    "- Operating conditions setup\n",
    "- Load and drive cell assignments\n",
    "\n",
    "### **üéØ Exercise 5: Netlist Instance Counter**\n",
    "Create a memory-efficient function that:\n",
    "- Counts instances of each cell type in a large netlist\n",
    "- Handles streaming input (doesn't load entire file)\n",
    "- Reports statistics (total instances, unique cell types)\n",
    "- Identifies the most frequently used cells\n",
    "\n",
    "### **üéØ Exercise 6: Design Hierarchy Validator**\n",
    "Implement a comprehensive validator that:\n",
    "- Checks hierarchy path syntax\n",
    "- Validates naming conventions\n",
    "- Detects circular references\n",
    "- Suggests corrections for invalid names\n",
    "\n",
    "---\n",
    "\n",
    "## üèÜ **Chapter Summary: String Mastery Achieved**\n",
    "\n",
    "Congratulations! You've mastered Python strings for professional VLSI automation:\n",
    "\n",
    "### **‚úÖ Core Concepts Mastered**\n",
    "- **String Creation**: 5+ methods including f-strings, raw strings, multi-line\n",
    "- **Properties**: Immutability, indexing, slicing, iteration, membership\n",
    "- **Essential Methods**: 25+ string methods for all common operations\n",
    "\n",
    "### **‚úÖ VLSI Applications Learned**\n",
    "- **Path Processing**: Hierarchical signal and file path manipulation\n",
    "- **Report Parsing**: Extract data from timing, power, and area reports\n",
    "- **Script Generation**: Create TCL, SDC, and configuration files\n",
    "- **Data Validation**: Robust input checking and sanitization\n",
    "\n",
    "### **‚úÖ Professional Techniques**\n",
    "- **Performance**: Efficient concatenation and memory management\n",
    "- **Error Handling**: Graceful failure recovery and validation\n",
    "- **Security**: Safe string processing and injection prevention\n",
    "- **Formatting**: Professional report generation and alignment\n",
    "\n",
    "### **‚úÖ Advanced Skills**\n",
    "- **Regular Expressions**: Complex pattern matching and extraction\n",
    "- **Large File Processing**: Memory-efficient streaming techniques\n",
    "- **Production Code**: Comprehensive error handling and validation\n",
    "\n",
    "### **üöÄ Next Steps**\n",
    "You're now ready to tackle any string processing challenge in VLSI automation. The techniques learned here will save hours of manual work and enable powerful automation scripts. \n",
    "\n",
    "**Recommended Practice**: Apply these concepts to your current VLSI projects‚Äîparse actual tool reports, generate real scripts, and build professional automation tools!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
